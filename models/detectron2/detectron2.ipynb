{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyyaml==5.1\n",
    "\n",
    "import torch\n",
    "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
    "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
    "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
    "# Install detectron2 that matches the above pytorch version\n",
    "# See https://detectron2.readthedocs.io/tutorials/install.html for instructions\n",
    "!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/$CUDA_VERSION/torch$TORCH_VERSION/index.html\n",
    "# If there is not yet a detectron2 release that matches the given torch + CUDA version, you need to install a different pytorch.\n",
    "\n",
    "# exit(0)  # After installation, you may need to \"restart runtime\" in Colab. This line can also restart runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some basic setup:\n",
    "# Setup detectron2 logger\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import os, json, cv2, random\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.data.datasets import register_coco_instances\n",
    "register_coco_instances(\"data_train\", {}, \"../../data/models/detectron2/train/_annotations.coco.json\", \"../../data/models/detectron2/train\")\n",
    "register_coco_instances(\"data_val\", {}, \"../../data/models/detectron2/valid/_annotations.coco.json\", \"../../data/models/detectron2/valid\")\n",
    "register_coco_instances(\"data_test\", {}, \"../../data/models/detectron2/test/_annotations.coco.json\", \"../../data/models/detectron2/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"data_train\",)\n",
    "cfg.DATASETS.TEST = (\"data_val\",)\n",
    "\n",
    "cfg.DATALOADER.NUM_WORKERS = 1\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml\")  # Let training initialize from model zoo\n",
    "cfg.SOLVER.IMS_PER_BATCH = 4\n",
    "cfg.SOLVER.BASE_LR = 0.001\n",
    "\n",
    "\n",
    "cfg.SOLVER.WARMUP_ITERS = 1000\n",
    "cfg.SOLVER.MAX_ITER = 1500 #adjust up if val mAP is still rising, adjust down if overfit\n",
    "#cfg.SOLVER.STEPS = (1000, 1500)\n",
    "cfg.SOLVER.STEPS = []\n",
    "cfg.SOLVER.GAMMA = 0.05\n",
    "\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 16\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 2 # n classes + 1\n",
    "\n",
    "cfg.TEST.EVAL_PERIOD = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.evaluation import COCOEvaluator\n",
    "\n",
    "class CocoTrainer(DefaultTrainer):\n",
    "\n",
    "  @classmethod\n",
    "  def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
    "\n",
    "    if output_folder is None:\n",
    "        os.makedirs(\"coco_eval\", exist_ok=True)\n",
    "        output_folder = \"coco_eval\"\n",
    "\n",
    "    return COCOEvaluator(dataset_name, cfg, False, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/15 20:15:22 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (6): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (7): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (8): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (9): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (10): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (11): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (12): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (13): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (14): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (15): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (16): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (17): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (18): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (19): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (20): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (21): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (22): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=3, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=8, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/15 20:15:22 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[12/15 20:15:22 d2.data.datasets.coco]: \u001b[0mLoaded 2559 images in COCO format from ../../data/models/detectron2/train/_annotations.coco.json\n",
      "\u001b[32m[12/15 20:15:22 d2.data.build]: \u001b[0mRemoved 475 images with no usable annotations. 2084 images left.\n",
      "\u001b[32m[12/15 20:15:22 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[12/15 20:15:22 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[12/15 20:15:22 d2.data.common]: \u001b[0mSerializing 2084 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/15 20:15:22 d2.data.common]: \u001b[0mSerialized dataset takes 0.73 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model_final_68b088.pkl: 421MB [01:43, 4.08MB/s]                               \n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (3, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (3,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (8, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (8,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/15 20:17:05 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gary Blackwood\\dev\\glasgow-litter\\venv\\lib\\site-packages\\torch\\functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ..\\aten\\src\\ATen\\native\\TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/15 20:17:41 d2.utils.events]: \u001b[0m eta: 0:27:13  iter: 19  total_loss: 3.136  loss_cls: 0.9554  loss_box_reg: 0.2783  loss_rpn_cls: 1.589  loss_rpn_loc: 0.1839  time: 1.1194  data_time: 0.1067  lr: 1.9981e-05  max_mem: 7616M\n",
      "\u001b[32m[12/15 20:18:02 d2.utils.events]: \u001b[0m eta: 0:26:49  iter: 39  total_loss: 1.826  loss_cls: 0.8223  loss_box_reg: 0.4991  loss_rpn_cls: 0.3997  loss_rpn_loc: 0.1078  time: 1.0803  data_time: 0.0406  lr: 3.9961e-05  max_mem: 7616M\n",
      "\u001b[32m[12/15 20:18:26 d2.utils.events]: \u001b[0m eta: 0:26:28  iter: 59  total_loss: 1.49  loss_cls: 0.6366  loss_box_reg: 0.624  loss_rpn_cls: 0.1376  loss_rpn_loc: 0.1262  time: 1.1205  data_time: 0.0421  lr: 5.9941e-05  max_mem: 7616M\n",
      "\u001b[32m[12/15 20:18:49 d2.utils.events]: \u001b[0m eta: 0:26:06  iter: 79  total_loss: 1.429  loss_cls: 0.5293  loss_box_reg: 0.6765  loss_rpn_cls: 0.09205  loss_rpn_loc: 0.1064  time: 1.1276  data_time: 0.0389  lr: 7.9921e-05  max_mem: 7616M\n",
      "\u001b[32m[12/15 20:19:13 d2.utils.events]: \u001b[0m eta: 0:25:53  iter: 99  total_loss: 1.424  loss_cls: 0.4263  loss_box_reg: 0.7509  loss_rpn_cls: 0.08726  loss_rpn_loc: 0.09971  time: 1.1396  data_time: 0.0400  lr: 9.9901e-05  max_mem: 7616M\n",
      "\u001b[32m[12/15 20:19:38 d2.utils.events]: \u001b[0m eta: 0:26:18  iter: 119  total_loss: 1.366  loss_cls: 0.3685  loss_box_reg: 0.7202  loss_rpn_cls: 0.1045  loss_rpn_loc: 0.1225  time: 1.1603  data_time: 0.0388  lr: 0.00011988  max_mem: 7616M\n",
      "\u001b[32m[12/15 20:20:02 d2.utils.events]: \u001b[0m eta: 0:26:16  iter: 139  total_loss: 1.157  loss_cls: 0.276  loss_box_reg: 0.7407  loss_rpn_cls: 0.0726  loss_rpn_loc: 0.0822  time: 1.1699  data_time: 0.0412  lr: 0.00013986  max_mem: 7616M\n",
      "\u001b[32m[12/15 20:20:26 d2.utils.events]: \u001b[0m eta: 0:25:55  iter: 159  total_loss: 1.129  loss_cls: 0.2485  loss_box_reg: 0.7204  loss_rpn_cls: 0.06955  loss_rpn_loc: 0.09391  time: 1.1702  data_time: 0.0448  lr: 0.00015984  max_mem: 7616M\n",
      "\u001b[32m[12/15 20:20:49 d2.utils.events]: \u001b[0m eta: 0:25:33  iter: 179  total_loss: 1.065  loss_cls: 0.2107  loss_box_reg: 0.669  loss_rpn_cls: 0.08098  loss_rpn_loc: 0.09718  time: 1.1717  data_time: 0.0488  lr: 0.00017982  max_mem: 7616M\n",
      "\u001b[32m[12/15 20:21:13 d2.utils.events]: \u001b[0m eta: 0:25:11  iter: 199  total_loss: 1.147  loss_cls: 0.243  loss_box_reg: 0.6585  loss_rpn_cls: 0.07835  loss_rpn_loc: 0.1179  time: 1.1741  data_time: 0.0434  lr: 0.0001998  max_mem: 7616M\n",
      "\u001b[32m[12/15 20:21:37 d2.utils.events]: \u001b[0m eta: 0:24:50  iter: 219  total_loss: 1.073  loss_cls: 0.2121  loss_box_reg: 0.7213  loss_rpn_cls: 0.07038  loss_rpn_loc: 0.09064  time: 1.1745  data_time: 0.0452  lr: 0.00021978  max_mem: 7616M\n",
      "\u001b[32m[12/15 20:22:01 d2.utils.events]: \u001b[0m eta: 0:24:28  iter: 239  total_loss: 1.013  loss_cls: 0.2306  loss_box_reg: 0.6937  loss_rpn_cls: 0.05619  loss_rpn_loc: 0.06928  time: 1.1766  data_time: 0.0438  lr: 0.00023976  max_mem: 7616M\n",
      "\u001b[32m[12/15 20:22:25 d2.utils.events]: \u001b[0m eta: 0:24:05  iter: 259  total_loss: 1.084  loss_cls: 0.209  loss_box_reg: 0.669  loss_rpn_cls: 0.06922  loss_rpn_loc: 0.08707  time: 1.1802  data_time: 0.0446  lr: 0.00025974  max_mem: 7616M\n",
      "\u001b[32m[12/15 20:22:48 d2.utils.events]: \u001b[0m eta: 0:23:42  iter: 279  total_loss: 1.106  loss_cls: 0.215  loss_box_reg: 0.6931  loss_rpn_cls: 0.0502  loss_rpn_loc: 0.09757  time: 1.1776  data_time: 0.0420  lr: 0.00027972  max_mem: 7616M\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/15 20:23:12 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[12/15 20:23:12 d2.data.datasets.coco]: \u001b[0mLoaded 244 images in COCO format from ../../data/models/detectron2/valid/_annotations.coco.json\n",
      "\u001b[32m[12/15 20:23:12 d2.data.build]: \u001b[0mDistribution of instances among all 2 categories:\n",
      "\u001b[36m|  category  | #instances   |  category  | #instances   |\n",
      "|:----------:|:-------------|:----------:|:-------------|\n",
      "|   litter   | 0            |   litter   | 446          |\n",
      "|            |              |            |              |\n",
      "|   total    | 446          |            |              |\u001b[0m\n",
      "\u001b[32m[12/15 20:23:12 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/15 20:23:12 d2.data.common]: \u001b[0mSerializing 244 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/15 20:23:12 d2.data.common]: \u001b[0mSerialized dataset takes 0.08 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/15 20:23:12 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[12/15 20:23:12 d2.evaluation.evaluator]: \u001b[0mStart inference on 244 batches\n",
      "\u001b[32m[12/15 20:23:15 d2.evaluation.evaluator]: \u001b[0mInference done 11/244. Dataloading: 0.0004 s/iter. Inference: 0.1490 s/iter. Eval: 0.0003 s/iter. Total: 0.1496 s/iter. ETA=0:00:34\n",
      "\u001b[32m[12/15 20:23:20 d2.evaluation.evaluator]: \u001b[0mInference done 45/244. Dataloading: 0.0004 s/iter. Inference: 0.1482 s/iter. Eval: 0.0003 s/iter. Total: 0.1489 s/iter. ETA=0:00:29\n",
      "\u001b[32m[12/15 20:23:25 d2.evaluation.evaluator]: \u001b[0mInference done 79/244. Dataloading: 0.0004 s/iter. Inference: 0.1482 s/iter. Eval: 0.0003 s/iter. Total: 0.1490 s/iter. ETA=0:00:24\n",
      "\u001b[32m[12/15 20:23:30 d2.evaluation.evaluator]: \u001b[0mInference done 113/244. Dataloading: 0.0004 s/iter. Inference: 0.1482 s/iter. Eval: 0.0003 s/iter. Total: 0.1489 s/iter. ETA=0:00:19\n",
      "\u001b[32m[12/15 20:23:35 d2.evaluation.evaluator]: \u001b[0mInference done 147/244. Dataloading: 0.0004 s/iter. Inference: 0.1483 s/iter. Eval: 0.0003 s/iter. Total: 0.1491 s/iter. ETA=0:00:14\n",
      "\u001b[32m[12/15 20:23:40 d2.evaluation.evaluator]: \u001b[0mInference done 181/244. Dataloading: 0.0004 s/iter. Inference: 0.1484 s/iter. Eval: 0.0003 s/iter. Total: 0.1491 s/iter. ETA=0:00:09\n",
      "\u001b[32m[12/15 20:23:45 d2.evaluation.evaluator]: \u001b[0mInference done 215/244. Dataloading: 0.0004 s/iter. Inference: 0.1485 s/iter. Eval: 0.0003 s/iter. Total: 0.1492 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/15 20:23:50 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:35.828230 (0.149909 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/15 20:23:50 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:35 (0.148524 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/15 20:23:50 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[12/15 20:23:50 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval\\coco_instances_results.json\n",
      "\u001b[32m[12/15 20:23:50 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.07s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[12/15 20:23:50 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[12/15 20:23:50 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.06 seconds.\n",
      "\u001b[32m[12/15 20:23:50 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[12/15 20:23:50 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.160\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.439\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.059\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.163\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.093\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.150\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.350\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.388\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.389\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.340\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.500\n",
      "\u001b[32m[12/15 20:23:50 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm  |  APl  |\n",
      "|:------:|:------:|:------:|:------:|:-----:|:-----:|\n",
      "| 16.040 | 43.940 | 5.923  | 16.318 | 9.330 | 0.109 |\n",
      "\u001b[32m[12/15 20:23:50 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP   | category   | AP     |\n",
      "|:-----------|:-----|:-----------|:-------|\n",
      "| litter     | nan  | litter     | 16.040 |\n",
      "\u001b[32m[12/15 20:23:50 d2.engine.defaults]: \u001b[0mEvaluation results for data_val in csv format:\n",
      "\u001b[32m[12/15 20:23:50 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[12/15 20:23:50 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[12/15 20:23:50 d2.evaluation.testing]: \u001b[0mcopypaste: 16.0397,43.9396,5.9230,16.3181,9.3305,0.1090\n",
      "\u001b[32m[12/15 20:23:50 d2.utils.events]: \u001b[0m eta: 0:23:20  iter: 299  total_loss: 1.052  loss_cls: 0.2174  loss_box_reg: 0.6585  loss_rpn_cls: 0.06011  loss_rpn_loc: 0.09243  time: 1.1779  data_time: 0.0456  lr: 0.0002997  max_mem: 7616M\n",
      "\u001b[32m[12/15 20:24:14 d2.utils.events]: \u001b[0m eta: 0:22:58  iter: 319  total_loss: 0.9917  loss_cls: 0.1596  loss_box_reg: 0.6249  loss_rpn_cls: 0.05328  loss_rpn_loc: 0.06993  time: 1.1795  data_time: 0.0442  lr: 0.00031968  max_mem: 7616M\n",
      "\u001b[32m[12/15 20:24:38 d2.utils.events]: \u001b[0m eta: 0:22:36  iter: 339  total_loss: 0.9667  loss_cls: 0.1789  loss_box_reg: 0.6385  loss_rpn_cls: 0.04522  loss_rpn_loc: 0.09686  time: 1.1807  data_time: 0.0421  lr: 0.00033966  max_mem: 7616M\n",
      "\u001b[32m[12/15 20:25:03 d2.utils.events]: \u001b[0m eta: 0:22:16  iter: 359  total_loss: 0.9507  loss_cls: 0.1722  loss_box_reg: 0.6567  loss_rpn_cls: 0.04642  loss_rpn_loc: 0.06999  time: 1.1827  data_time: 0.0468  lr: 0.00035964  max_mem: 7616M\n",
      "\u001b[32m[12/15 20:25:27 d2.utils.events]: \u001b[0m eta: 0:21:55  iter: 379  total_loss: 0.9821  loss_cls: 0.1796  loss_box_reg: 0.6685  loss_rpn_cls: 0.04315  loss_rpn_loc: 0.08037  time: 1.1837  data_time: 0.0466  lr: 0.00037962  max_mem: 7616M\n",
      "\u001b[32m[12/15 20:25:51 d2.utils.events]: \u001b[0m eta: 0:21:31  iter: 399  total_loss: 0.9989  loss_cls: 0.1688  loss_box_reg: 0.6668  loss_rpn_cls: 0.0449  loss_rpn_loc: 0.1032  time: 1.1841  data_time: 0.0434  lr: 0.0003996  max_mem: 7616M\n",
      "\u001b[32m[12/15 20:26:14 d2.utils.events]: \u001b[0m eta: 0:21:08  iter: 419  total_loss: 1.028  loss_cls: 0.1833  loss_box_reg: 0.6726  loss_rpn_cls: 0.06268  loss_rpn_loc: 0.1103  time: 1.1840  data_time: 0.0453  lr: 0.00041958  max_mem: 7616M\n",
      "\u001b[32m[12/15 20:26:38 d2.utils.events]: \u001b[0m eta: 0:20:45  iter: 439  total_loss: 0.9664  loss_cls: 0.1589  loss_box_reg: 0.6866  loss_rpn_cls: 0.03979  loss_rpn_loc: 0.07962  time: 1.1848  data_time: 0.0439  lr: 0.00043956  max_mem: 7616M\n",
      "\u001b[32m[12/15 20:27:03 d2.utils.events]: \u001b[0m eta: 0:20:23  iter: 459  total_loss: 0.9591  loss_cls: 0.1805  loss_box_reg: 0.6282  loss_rpn_cls: 0.03666  loss_rpn_loc: 0.0804  time: 1.1873  data_time: 0.0469  lr: 0.00045954  max_mem: 7616M\n",
      "\u001b[32m[12/15 20:27:28 d2.utils.events]: \u001b[0m eta: 0:20:00  iter: 479  total_loss: 1.024  loss_cls: 0.2363  loss_box_reg: 0.6485  loss_rpn_cls: 0.04618  loss_rpn_loc: 0.0862  time: 1.1899  data_time: 0.0454  lr: 0.00047952  max_mem: 7616M\n",
      "\u001b[32m[12/15 20:27:51 d2.utils.events]: \u001b[0m eta: 0:19:35  iter: 499  total_loss: 1.005  loss_cls: 0.209  loss_box_reg: 0.6332  loss_rpn_cls: 0.05203  loss_rpn_loc: 0.09895  time: 1.1872  data_time: 0.0446  lr: 0.0004995  max_mem: 7616M\n",
      "\u001b[32m[12/15 20:28:15 d2.utils.events]: \u001b[0m eta: 0:19:12  iter: 519  total_loss: 1.047  loss_cls: 0.2052  loss_box_reg: 0.6718  loss_rpn_cls: 0.04912  loss_rpn_loc: 0.09124  time: 1.1884  data_time: 0.0465  lr: 0.00051948  max_mem: 7616M\n",
      "\u001b[32m[12/15 20:28:39 d2.utils.events]: \u001b[0m eta: 0:18:49  iter: 539  total_loss: 0.9868  loss_cls: 0.1807  loss_box_reg: 0.627  loss_rpn_cls: 0.04625  loss_rpn_loc: 0.08913  time: 1.1882  data_time: 0.0338  lr: 0.00053946  max_mem: 7616M\n",
      "\u001b[32m[12/15 20:29:03 d2.utils.events]: \u001b[0m eta: 0:18:27  iter: 559  total_loss: 0.985  loss_cls: 0.1617  loss_box_reg: 0.6312  loss_rpn_cls: 0.0414  loss_rpn_loc: 0.093  time: 1.1892  data_time: 0.0334  lr: 0.00055944  max_mem: 7616M\n",
      "\u001b[32m[12/15 20:29:27 d2.utils.events]: \u001b[0m eta: 0:18:06  iter: 579  total_loss: 0.9301  loss_cls: 0.1576  loss_box_reg: 0.6443  loss_rpn_cls: 0.03426  loss_rpn_loc: 0.08893  time: 1.1898  data_time: 0.0365  lr: 0.00057942  max_mem: 7616M\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/15 20:29:52 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[12/15 20:29:52 d2.data.datasets.coco]: \u001b[0mLoaded 244 images in COCO format from ../../data/models/detectron2/valid/_annotations.coco.json\n",
      "\u001b[32m[12/15 20:29:52 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/15 20:29:52 d2.data.common]: \u001b[0mSerializing 244 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/15 20:29:52 d2.data.common]: \u001b[0mSerialized dataset takes 0.08 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/15 20:29:52 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[12/15 20:29:52 d2.evaluation.evaluator]: \u001b[0mStart inference on 244 batches\n",
      "\u001b[32m[12/15 20:29:55 d2.evaluation.evaluator]: \u001b[0mInference done 11/244. Dataloading: 0.0004 s/iter. Inference: 0.1431 s/iter. Eval: 0.0002 s/iter. Total: 0.1437 s/iter. ETA=0:00:33\n",
      "\u001b[32m[12/15 20:30:00 d2.evaluation.evaluator]: \u001b[0mInference done 48/244. Dataloading: 0.0004 s/iter. Inference: 0.1374 s/iter. Eval: 0.0003 s/iter. Total: 0.1381 s/iter. ETA=0:00:27\n",
      "\u001b[32m[12/15 20:30:05 d2.evaluation.evaluator]: \u001b[0mInference done 81/244. Dataloading: 0.0004 s/iter. Inference: 0.1434 s/iter. Eval: 0.0003 s/iter. Total: 0.1442 s/iter. ETA=0:00:23\n",
      "\u001b[32m[12/15 20:30:10 d2.evaluation.evaluator]: \u001b[0mInference done 114/244. Dataloading: 0.0004 s/iter. Inference: 0.1461 s/iter. Eval: 0.0003 s/iter. Total: 0.1469 s/iter. ETA=0:00:19\n",
      "\u001b[32m[12/15 20:30:15 d2.evaluation.evaluator]: \u001b[0mInference done 147/244. Dataloading: 0.0004 s/iter. Inference: 0.1473 s/iter. Eval: 0.0003 s/iter. Total: 0.1480 s/iter. ETA=0:00:14\n",
      "\u001b[32m[12/15 20:30:20 d2.evaluation.evaluator]: \u001b[0mInference done 184/244. Dataloading: 0.0004 s/iter. Inference: 0.1453 s/iter. Eval: 0.0003 s/iter. Total: 0.1461 s/iter. ETA=0:00:08\n",
      "\u001b[32m[12/15 20:30:25 d2.evaluation.evaluator]: \u001b[0mInference done 221/244. Dataloading: 0.0004 s/iter. Inference: 0.1436 s/iter. Eval: 0.0003 s/iter. Total: 0.1444 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/15 20:30:29 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:34.854670 (0.145835 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/15 20:30:29 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:34 (0.144251 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/15 20:30:29 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[12/15 20:30:29 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval\\coco_instances_results.json\n",
      "\u001b[32m[12/15 20:30:29 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[12/15 20:30:29 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[12/15 20:30:29 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.13 seconds.\n",
      "\u001b[32m[12/15 20:30:29 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[12/15 20:30:29 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.01 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.203\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.550\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.074\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.209\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.057\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.033\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.177\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.380\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.411\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.410\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.460\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.500\n",
      "\u001b[32m[12/15 20:30:29 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm  |  APl  |\n",
      "|:------:|:------:|:------:|:------:|:-----:|:-----:|\n",
      "| 20.348 | 55.038 | 7.424  | 20.863 | 5.677 | 3.333 |\n",
      "\u001b[32m[12/15 20:30:29 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP   | category   | AP     |\n",
      "|:-----------|:-----|:-----------|:-------|\n",
      "| litter     | nan  | litter     | 20.348 |\n",
      "\u001b[32m[12/15 20:30:29 d2.engine.defaults]: \u001b[0mEvaluation results for data_val in csv format:\n",
      "\u001b[32m[12/15 20:30:29 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[12/15 20:30:29 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[12/15 20:30:29 d2.evaluation.testing]: \u001b[0mcopypaste: 20.3485,55.0383,7.4236,20.8629,5.6773,3.3333\n",
      "\u001b[32m[12/15 20:30:29 d2.utils.events]: \u001b[0m eta: 0:17:43  iter: 599  total_loss: 0.9506  loss_cls: 0.1802  loss_box_reg: 0.5911  loss_rpn_cls: 0.04068  loss_rpn_loc: 0.0914  time: 1.1913  data_time: 0.0347  lr: 0.0005994  max_mem: 7616M\n",
      "\u001b[32m[12/15 20:30:51 d2.utils.events]: \u001b[0m eta: 0:17:15  iter: 619  total_loss: 0.9789  loss_cls: 0.2016  loss_box_reg: 0.6572  loss_rpn_cls: 0.03315  loss_rpn_loc: 0.09637  time: 1.1878  data_time: 0.0334  lr: 0.00061938  max_mem: 7616M\n",
      "\u001b[32m[12/15 20:31:13 d2.utils.events]: \u001b[0m eta: 0:16:50  iter: 639  total_loss: 0.9083  loss_cls: 0.171  loss_box_reg: 0.5812  loss_rpn_cls: 0.05092  loss_rpn_loc: 0.08626  time: 1.1855  data_time: 0.0332  lr: 0.00063936  max_mem: 7616M\n",
      "\u001b[32m[12/15 20:31:35 d2.utils.events]: \u001b[0m eta: 0:16:24  iter: 659  total_loss: 0.863  loss_cls: 0.1621  loss_box_reg: 0.587  loss_rpn_cls: 0.03352  loss_rpn_loc: 0.06943  time: 1.1827  data_time: 0.0335  lr: 0.00065934  max_mem: 7616M\n",
      "\u001b[32m[12/15 20:31:59 d2.utils.events]: \u001b[0m eta: 0:16:01  iter: 679  total_loss: 0.9712  loss_cls: 0.1497  loss_box_reg: 0.6509  loss_rpn_cls: 0.03217  loss_rpn_loc: 0.07775  time: 1.1831  data_time: 0.0398  lr: 0.00067932  max_mem: 7616M\n",
      "\u001b[32m[12/15 20:32:21 d2.utils.events]: \u001b[0m eta: 0:15:36  iter: 699  total_loss: 0.9246  loss_cls: 0.1398  loss_box_reg: 0.6571  loss_rpn_cls: 0.03516  loss_rpn_loc: 0.08935  time: 1.1805  data_time: 0.0334  lr: 0.0006993  max_mem: 7616M\n",
      "\u001b[32m[12/15 20:32:44 d2.utils.events]: \u001b[0m eta: 0:15:12  iter: 719  total_loss: 0.9567  loss_cls: 0.198  loss_box_reg: 0.6752  loss_rpn_cls: 0.03303  loss_rpn_loc: 0.06987  time: 1.1799  data_time: 0.0340  lr: 0.00071928  max_mem: 7616M\n",
      "\u001b[32m[12/15 20:33:15 d2.utils.events]: \u001b[0m eta: 0:14:51  iter: 739  total_loss: 0.9509  loss_cls: 0.1671  loss_box_reg: 0.6393  loss_rpn_cls: 0.03691  loss_rpn_loc: 0.08926  time: 1.1903  data_time: 0.0385  lr: 0.00073926  max_mem: 7616M\n",
      "\u001b[32m[12/15 20:33:46 d2.utils.events]: \u001b[0m eta: 0:14:29  iter: 759  total_loss: 0.9137  loss_cls: 0.1623  loss_box_reg: 0.6393  loss_rpn_cls: 0.04179  loss_rpn_loc: 0.0882  time: 1.1996  data_time: 0.0327  lr: 0.00075924  max_mem: 7616M\n",
      "\u001b[32m[12/15 20:34:17 d2.utils.events]: \u001b[0m eta: 0:14:08  iter: 779  total_loss: 0.8766  loss_cls: 0.1403  loss_box_reg: 0.6254  loss_rpn_cls: 0.02881  loss_rpn_loc: 0.07595  time: 1.2089  data_time: 0.0340  lr: 0.00077922  max_mem: 7616M\n",
      "\u001b[32m[12/15 20:34:47 d2.utils.events]: \u001b[0m eta: 0:14:01  iter: 799  total_loss: 0.9386  loss_cls: 0.1733  loss_box_reg: 0.6756  loss_rpn_cls: 0.03347  loss_rpn_loc: 0.09003  time: 1.2160  data_time: 0.0331  lr: 0.0007992  max_mem: 7616M\n",
      "\u001b[32m[12/15 20:35:19 d2.utils.events]: \u001b[0m eta: 0:13:52  iter: 819  total_loss: 0.9348  loss_cls: 0.1521  loss_box_reg: 0.6023  loss_rpn_cls: 0.04047  loss_rpn_loc: 0.09847  time: 1.2251  data_time: 0.0328  lr: 0.00081918  max_mem: 7616M\n",
      "\u001b[32m[12/15 20:35:51 d2.utils.events]: \u001b[0m eta: 0:13:36  iter: 839  total_loss: 0.8782  loss_cls: 0.1398  loss_box_reg: 0.6441  loss_rpn_cls: 0.03176  loss_rpn_loc: 0.09794  time: 1.2345  data_time: 0.0344  lr: 0.00083916  max_mem: 7616M\n",
      "\u001b[32m[12/15 20:36:23 d2.utils.events]: \u001b[0m eta: 0:13:14  iter: 859  total_loss: 0.9259  loss_cls: 0.1228  loss_box_reg: 0.6678  loss_rpn_cls: 0.0306  loss_rpn_loc: 0.1113  time: 1.2424  data_time: 0.0347  lr: 0.00085914  max_mem: 7616M\n",
      "\u001b[32m[12/15 20:36:53 d2.utils.events]: \u001b[0m eta: 0:12:50  iter: 879  total_loss: 0.905  loss_cls: 0.1501  loss_box_reg: 0.6149  loss_rpn_cls: 0.0256  loss_rpn_loc: 0.07562  time: 1.2485  data_time: 0.0329  lr: 0.00087912  max_mem: 7616M\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/15 20:37:24 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[12/15 20:37:24 d2.data.datasets.coco]: \u001b[0mLoaded 244 images in COCO format from ../../data/models/detectron2/valid/_annotations.coco.json\n",
      "\u001b[32m[12/15 20:37:24 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/15 20:37:24 d2.data.common]: \u001b[0mSerializing 244 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/15 20:37:24 d2.data.common]: \u001b[0mSerialized dataset takes 0.08 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/15 20:37:24 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[12/15 20:37:24 d2.evaluation.evaluator]: \u001b[0mStart inference on 244 batches\n",
      "\u001b[32m[12/15 20:37:27 d2.evaluation.evaluator]: \u001b[0mInference done 11/244. Dataloading: 0.0003 s/iter. Inference: 0.1923 s/iter. Eval: 0.0002 s/iter. Total: 0.1929 s/iter. ETA=0:00:44\n",
      "\u001b[32m[12/15 20:37:32 d2.evaluation.evaluator]: \u001b[0mInference done 38/244. Dataloading: 0.0004 s/iter. Inference: 0.1906 s/iter. Eval: 0.0002 s/iter. Total: 0.1913 s/iter. ETA=0:00:39\n",
      "\u001b[32m[12/15 20:37:38 d2.evaluation.evaluator]: \u001b[0mInference done 65/244. Dataloading: 0.0004 s/iter. Inference: 0.1904 s/iter. Eval: 0.0003 s/iter. Total: 0.1911 s/iter. ETA=0:00:34\n",
      "\u001b[32m[12/15 20:37:43 d2.evaluation.evaluator]: \u001b[0mInference done 92/244. Dataloading: 0.0004 s/iter. Inference: 0.1902 s/iter. Eval: 0.0003 s/iter. Total: 0.1909 s/iter. ETA=0:00:29\n",
      "\u001b[32m[12/15 20:37:48 d2.evaluation.evaluator]: \u001b[0mInference done 119/244. Dataloading: 0.0004 s/iter. Inference: 0.1906 s/iter. Eval: 0.0003 s/iter. Total: 0.1913 s/iter. ETA=0:00:23\n",
      "\u001b[32m[12/15 20:37:53 d2.evaluation.evaluator]: \u001b[0mInference done 146/244. Dataloading: 0.0004 s/iter. Inference: 0.1897 s/iter. Eval: 0.0002 s/iter. Total: 0.1904 s/iter. ETA=0:00:18\n",
      "\u001b[32m[12/15 20:37:58 d2.evaluation.evaluator]: \u001b[0mInference done 173/244. Dataloading: 0.0004 s/iter. Inference: 0.1897 s/iter. Eval: 0.0002 s/iter. Total: 0.1904 s/iter. ETA=0:00:13\n",
      "\u001b[32m[12/15 20:38:03 d2.evaluation.evaluator]: \u001b[0mInference done 200/244. Dataloading: 0.0004 s/iter. Inference: 0.1898 s/iter. Eval: 0.0002 s/iter. Total: 0.1905 s/iter. ETA=0:00:08\n",
      "\u001b[32m[12/15 20:38:08 d2.evaluation.evaluator]: \u001b[0mInference done 227/244. Dataloading: 0.0004 s/iter. Inference: 0.1898 s/iter. Eval: 0.0002 s/iter. Total: 0.1905 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/15 20:38:12 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:45.698038 (0.191205 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/15 20:38:12 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:45 (0.189895 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/15 20:38:12 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[12/15 20:38:12 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval\\coco_instances_results.json\n",
      "\u001b[32m[12/15 20:38:12 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[12/15 20:38:12 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[12/15 20:38:12 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.03 seconds.\n",
      "\u001b[32m[12/15 20:38:12 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[12/15 20:38:12 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.01 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.200\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.559\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.065\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.202\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.176\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.400\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.176\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.393\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.409\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.407\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.470\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.400\n",
      "\u001b[32m[12/15 20:38:12 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 20.039 | 55.948 | 6.459  | 20.247 | 17.551 | 40.000 |\n",
      "\u001b[32m[12/15 20:38:12 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP   | category   | AP     |\n",
      "|:-----------|:-----|:-----------|:-------|\n",
      "| litter     | nan  | litter     | 20.039 |\n",
      "\u001b[32m[12/15 20:38:12 d2.engine.defaults]: \u001b[0mEvaluation results for data_val in csv format:\n",
      "\u001b[32m[12/15 20:38:12 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[12/15 20:38:12 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[12/15 20:38:12 d2.evaluation.testing]: \u001b[0mcopypaste: 20.0388,55.9479,6.4589,20.2469,17.5506,40.0000\n",
      "\u001b[32m[12/15 20:38:12 d2.utils.events]: \u001b[0m eta: 0:12:26  iter: 899  total_loss: 0.8665  loss_cls: 0.1129  loss_box_reg: 0.6033  loss_rpn_cls: 0.02907  loss_rpn_loc: 0.08704  time: 1.2551  data_time: 0.0349  lr: 0.0008991  max_mem: 7616M\n",
      "\u001b[32m[12/15 20:38:44 d2.utils.events]: \u001b[0m eta: 0:12:02  iter: 919  total_loss: 0.9126  loss_cls: 0.1867  loss_box_reg: 0.5794  loss_rpn_cls: 0.04031  loss_rpn_loc: 0.07022  time: 1.2624  data_time: 0.0321  lr: 0.00091908  max_mem: 7616M\n",
      "\u001b[32m[12/15 20:39:14 d2.utils.events]: \u001b[0m eta: 0:11:37  iter: 939  total_loss: 0.9262  loss_cls: 0.1923  loss_box_reg: 0.6145  loss_rpn_cls: 0.02864  loss_rpn_loc: 0.0842  time: 1.2675  data_time: 0.0335  lr: 0.00093906  max_mem: 7616M\n",
      "\u001b[32m[12/15 20:39:44 d2.utils.events]: \u001b[0m eta: 0:11:13  iter: 959  total_loss: 0.9509  loss_cls: 0.1899  loss_box_reg: 0.632  loss_rpn_cls: 0.0254  loss_rpn_loc: 0.0799  time: 1.2727  data_time: 0.0337  lr: 0.00095904  max_mem: 7616M\n",
      "\u001b[32m[12/15 20:40:15 d2.utils.events]: \u001b[0m eta: 0:10:48  iter: 979  total_loss: 0.9804  loss_cls: 0.1612  loss_box_reg: 0.6334  loss_rpn_cls: 0.02888  loss_rpn_loc: 0.09485  time: 1.2784  data_time: 0.0345  lr: 0.00097902  max_mem: 7616M\n",
      "\u001b[32m[12/15 20:40:47 d2.utils.events]: \u001b[0m eta: 0:10:24  iter: 999  total_loss: 0.8945  loss_cls: 0.1689  loss_box_reg: 0.6066  loss_rpn_cls: 0.02473  loss_rpn_loc: 0.07688  time: 1.2844  data_time: 0.0354  lr: 0.000999  max_mem: 7616M\n",
      "\u001b[32m[12/15 20:41:18 d2.utils.events]: \u001b[0m eta: 0:09:59  iter: 1019  total_loss: 0.9241  loss_cls: 0.1809  loss_box_reg: 0.6431  loss_rpn_cls: 0.0335  loss_rpn_loc: 0.1033  time: 1.2901  data_time: 0.0343  lr: 0.001  max_mem: 7616M\n",
      "\u001b[32m[12/15 20:41:49 d2.utils.events]: \u001b[0m eta: 0:09:35  iter: 1039  total_loss: 0.9569  loss_cls: 0.1625  loss_box_reg: 0.6121  loss_rpn_cls: 0.04308  loss_rpn_loc: 0.08427  time: 1.2951  data_time: 0.0330  lr: 0.001  max_mem: 7616M\n",
      "\u001b[32m[12/15 20:42:20 d2.utils.events]: \u001b[0m eta: 0:09:10  iter: 1059  total_loss: 0.899  loss_cls: 0.1589  loss_box_reg: 0.5645  loss_rpn_cls: 0.02866  loss_rpn_loc: 0.08415  time: 1.2999  data_time: 0.0333  lr: 0.001  max_mem: 7616M\n",
      "\u001b[32m[12/15 20:42:50 d2.utils.events]: \u001b[0m eta: 0:08:46  iter: 1079  total_loss: 0.9331  loss_cls: 0.1645  loss_box_reg: 0.6325  loss_rpn_cls: 0.03384  loss_rpn_loc: 0.09209  time: 1.3036  data_time: 0.0335  lr: 0.001  max_mem: 7616M\n",
      "\u001b[32m[12/15 20:43:21 d2.utils.events]: \u001b[0m eta: 0:08:21  iter: 1099  total_loss: 0.9441  loss_cls: 0.2074  loss_box_reg: 0.5862  loss_rpn_cls: 0.02434  loss_rpn_loc: 0.08078  time: 1.3076  data_time: 0.0394  lr: 0.001  max_mem: 7616M\n",
      "\u001b[32m[12/15 20:43:52 d2.utils.events]: \u001b[0m eta: 0:07:57  iter: 1119  total_loss: 0.8771  loss_cls: 0.1593  loss_box_reg: 0.6156  loss_rpn_cls: 0.02807  loss_rpn_loc: 0.0802  time: 1.3122  data_time: 0.0377  lr: 0.001  max_mem: 7616M\n",
      "\u001b[32m[12/15 20:44:23 d2.utils.events]: \u001b[0m eta: 0:07:32  iter: 1139  total_loss: 0.9001  loss_cls: 0.1223  loss_box_reg: 0.6222  loss_rpn_cls: 0.02024  loss_rpn_loc: 0.06904  time: 1.3164  data_time: 0.0349  lr: 0.001  max_mem: 7616M\n",
      "\u001b[32m[12/15 20:44:55 d2.utils.events]: \u001b[0m eta: 0:07:08  iter: 1159  total_loss: 0.8957  loss_cls: 0.1404  loss_box_reg: 0.6132  loss_rpn_cls: 0.02525  loss_rpn_loc: 0.0796  time: 1.3212  data_time: 0.0384  lr: 0.001  max_mem: 7616M\n",
      "\u001b[32m[12/15 20:45:25 d2.utils.events]: \u001b[0m eta: 0:06:45  iter: 1179  total_loss: 0.9177  loss_cls: 0.1755  loss_box_reg: 0.5948  loss_rpn_cls: 0.02901  loss_rpn_loc: 0.0847  time: 1.3240  data_time: 0.0360  lr: 0.001  max_mem: 7616M\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/15 20:45:55 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[12/15 20:45:55 d2.data.datasets.coco]: \u001b[0mLoaded 244 images in COCO format from ../../data/models/detectron2/valid/_annotations.coco.json\n",
      "\u001b[32m[12/15 20:45:55 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/15 20:45:55 d2.data.common]: \u001b[0mSerializing 244 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/15 20:45:55 d2.data.common]: \u001b[0mSerialized dataset takes 0.08 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/15 20:45:55 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[12/15 20:45:55 d2.evaluation.evaluator]: \u001b[0mStart inference on 244 batches\n",
      "\u001b[32m[12/15 20:45:59 d2.evaluation.evaluator]: \u001b[0mInference done 11/244. Dataloading: 0.0003 s/iter. Inference: 0.1930 s/iter. Eval: 0.0002 s/iter. Total: 0.1935 s/iter. ETA=0:00:45\n",
      "\u001b[32m[12/15 20:46:04 d2.evaluation.evaluator]: \u001b[0mInference done 38/244. Dataloading: 0.0004 s/iter. Inference: 0.1914 s/iter. Eval: 0.0003 s/iter. Total: 0.1921 s/iter. ETA=0:00:39\n",
      "\u001b[32m[12/15 20:46:09 d2.evaluation.evaluator]: \u001b[0mInference done 65/244. Dataloading: 0.0004 s/iter. Inference: 0.1913 s/iter. Eval: 0.0002 s/iter. Total: 0.1920 s/iter. ETA=0:00:34\n",
      "\u001b[32m[12/15 20:46:14 d2.evaluation.evaluator]: \u001b[0mInference done 92/244. Dataloading: 0.0004 s/iter. Inference: 0.1911 s/iter. Eval: 0.0003 s/iter. Total: 0.1918 s/iter. ETA=0:00:29\n",
      "\u001b[32m[12/15 20:46:20 d2.evaluation.evaluator]: \u001b[0mInference done 119/244. Dataloading: 0.0004 s/iter. Inference: 0.1909 s/iter. Eval: 0.0003 s/iter. Total: 0.1916 s/iter. ETA=0:00:23\n",
      "\u001b[32m[12/15 20:46:25 d2.evaluation.evaluator]: \u001b[0mInference done 146/244. Dataloading: 0.0004 s/iter. Inference: 0.1909 s/iter. Eval: 0.0003 s/iter. Total: 0.1916 s/iter. ETA=0:00:18\n",
      "\u001b[32m[12/15 20:46:30 d2.evaluation.evaluator]: \u001b[0mInference done 172/244. Dataloading: 0.0004 s/iter. Inference: 0.1913 s/iter. Eval: 0.0003 s/iter. Total: 0.1921 s/iter. ETA=0:00:13\n",
      "\u001b[32m[12/15 20:46:35 d2.evaluation.evaluator]: \u001b[0mInference done 198/244. Dataloading: 0.0004 s/iter. Inference: 0.1914 s/iter. Eval: 0.0003 s/iter. Total: 0.1921 s/iter. ETA=0:00:08\n",
      "\u001b[32m[12/15 20:46:40 d2.evaluation.evaluator]: \u001b[0mInference done 224/244. Dataloading: 0.0004 s/iter. Inference: 0.1915 s/iter. Eval: 0.0003 s/iter. Total: 0.1922 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/15 20:46:44 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:46.073983 (0.192778 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/15 20:46:44 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:45 (0.191470 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/15 20:46:44 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[12/15 20:46:44 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval\\coco_instances_results.json\n",
      "\u001b[32m[12/15 20:46:44 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[12/15 20:46:44 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[12/15 20:46:44 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.02 seconds.\n",
      "\u001b[32m[12/15 20:46:44 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[12/15 20:46:44 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.01 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.238\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.608\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.121\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.237\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.237\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.400\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.219\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.418\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.435\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.435\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.470\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.400\n",
      "\u001b[32m[12/15 20:46:44 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 23.800 | 60.772 | 12.061 | 23.725 | 23.725 | 40.000 |\n",
      "\u001b[32m[12/15 20:46:44 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP   | category   | AP     |\n",
      "|:-----------|:-----|:-----------|:-------|\n",
      "| litter     | nan  | litter     | 23.800 |\n",
      "\u001b[32m[12/15 20:46:44 d2.engine.defaults]: \u001b[0mEvaluation results for data_val in csv format:\n",
      "\u001b[32m[12/15 20:46:44 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[12/15 20:46:44 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[12/15 20:46:44 d2.evaluation.testing]: \u001b[0mcopypaste: 23.7997,60.7720,12.0607,23.7251,23.7249,40.0000\n",
      "\u001b[32m[12/15 20:46:44 d2.utils.events]: \u001b[0m eta: 0:06:22  iter: 1199  total_loss: 0.8714  loss_cls: 0.1456  loss_box_reg: 0.5954  loss_rpn_cls: 0.02489  loss_rpn_loc: 0.07112  time: 1.3276  data_time: 0.0340  lr: 0.001  max_mem: 7616M\n",
      "\u001b[32m[12/15 20:47:15 d2.utils.events]: \u001b[0m eta: 0:06:04  iter: 1219  total_loss: 0.9653  loss_cls: 0.1518  loss_box_reg: 0.6322  loss_rpn_cls: 0.02562  loss_rpn_loc: 0.07566  time: 1.3315  data_time: 0.0361  lr: 0.001  max_mem: 7616M\n",
      "\u001b[32m[12/15 20:47:46 d2.utils.events]: \u001b[0m eta: 0:05:44  iter: 1239  total_loss: 0.8903  loss_cls: 0.1553  loss_box_reg: 0.6013  loss_rpn_cls: 0.01842  loss_rpn_loc: 0.08129  time: 1.3349  data_time: 0.0435  lr: 0.001  max_mem: 7616M\n",
      "\u001b[32m[12/15 20:48:17 d2.utils.events]: \u001b[0m eta: 0:05:32  iter: 1259  total_loss: 0.9093  loss_cls: 0.1714  loss_box_reg: 0.6313  loss_rpn_cls: 0.03151  loss_rpn_loc: 0.06876  time: 1.3385  data_time: 0.0377  lr: 0.001  max_mem: 7616M\n",
      "\u001b[32m[12/15 20:48:48 d2.utils.events]: \u001b[0m eta: 0:05:08  iter: 1279  total_loss: 0.9101  loss_cls: 0.1504  loss_box_reg: 0.6333  loss_rpn_cls: 0.02928  loss_rpn_loc: 0.07144  time: 1.3419  data_time: 0.0398  lr: 0.001  max_mem: 7616M\n",
      "\u001b[32m[12/15 20:49:20 d2.utils.events]: \u001b[0m eta: 0:04:42  iter: 1299  total_loss: 0.9026  loss_cls: 0.1812  loss_box_reg: 0.6031  loss_rpn_cls: 0.03344  loss_rpn_loc: 0.0763  time: 1.3452  data_time: 0.0362  lr: 0.001  max_mem: 7616M\n",
      "\u001b[32m[12/15 20:49:51 d2.utils.events]: \u001b[0m eta: 0:04:14  iter: 1319  total_loss: 0.9122  loss_cls: 0.1717  loss_box_reg: 0.6219  loss_rpn_cls: 0.02863  loss_rpn_loc: 0.0755  time: 1.3484  data_time: 0.0365  lr: 0.001  max_mem: 7616M\n",
      "\u001b[32m[12/15 20:50:19 d2.utils.events]: \u001b[0m eta: 0:03:47  iter: 1339  total_loss: 0.8808  loss_cls: 0.1498  loss_box_reg: 0.5796  loss_rpn_cls: 0.02266  loss_rpn_loc: 0.08642  time: 1.3496  data_time: 0.0345  lr: 0.001  max_mem: 7616M\n",
      "\u001b[32m[12/15 20:50:44 d2.utils.events]: \u001b[0m eta: 0:03:18  iter: 1359  total_loss: 0.9105  loss_cls: 0.1497  loss_box_reg: 0.643  loss_rpn_cls: 0.02006  loss_rpn_loc: 0.08363  time: 1.3478  data_time: 0.0339  lr: 0.001  max_mem: 7616M\n",
      "\u001b[32m[12/15 20:51:08 d2.utils.events]: \u001b[0m eta: 0:02:50  iter: 1379  total_loss: 0.9291  loss_cls: 0.1549  loss_box_reg: 0.6613  loss_rpn_cls: 0.02957  loss_rpn_loc: 0.09189  time: 1.3457  data_time: 0.0338  lr: 0.001  max_mem: 7616M\n",
      "\u001b[32m[12/15 20:51:33 d2.utils.events]: \u001b[0m eta: 0:02:22  iter: 1399  total_loss: 0.9466  loss_cls: 0.1353  loss_box_reg: 0.6355  loss_rpn_cls: 0.03932  loss_rpn_loc: 0.08207  time: 1.3447  data_time: 0.0356  lr: 0.001  max_mem: 7616M\n",
      "\u001b[32m[12/15 20:51:58 d2.utils.events]: \u001b[0m eta: 0:01:53  iter: 1419  total_loss: 0.8728  loss_cls: 0.1289  loss_box_reg: 0.5699  loss_rpn_cls: 0.02786  loss_rpn_loc: 0.08395  time: 1.3434  data_time: 0.0343  lr: 0.001  max_mem: 7616M\n",
      "\u001b[32m[12/15 20:52:22 d2.utils.events]: \u001b[0m eta: 0:01:25  iter: 1439  total_loss: 0.7757  loss_cls: 0.1321  loss_box_reg: 0.5639  loss_rpn_cls: 0.02014  loss_rpn_loc: 0.07305  time: 1.3410  data_time: 0.0353  lr: 0.001  max_mem: 7616M\n",
      "\u001b[32m[12/15 20:52:48 d2.utils.events]: \u001b[0m eta: 0:00:57  iter: 1459  total_loss: 0.9281  loss_cls: 0.1206  loss_box_reg: 0.6452  loss_rpn_cls: 0.03337  loss_rpn_loc: 0.08173  time: 1.3408  data_time: 0.0345  lr: 0.001  max_mem: 7616M\n",
      "\u001b[32m[12/15 20:53:13 d2.utils.events]: \u001b[0m eta: 0:00:28  iter: 1479  total_loss: 0.881  loss_cls: 0.1489  loss_box_reg: 0.594  loss_rpn_cls: 0.02159  loss_rpn_loc: 0.08403  time: 1.3390  data_time: 0.0345  lr: 0.001  max_mem: 7616M\n",
      "\u001b[32m[12/15 20:53:37 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 1499  total_loss: 0.841  loss_cls: 0.1189  loss_box_reg: 0.6287  loss_rpn_cls: 0.02678  loss_rpn_loc: 0.07215  time: 1.3365  data_time: 0.0336  lr: 0.001  max_mem: 7616M\n",
      "\u001b[32m[12/15 20:53:37 d2.engine.hooks]: \u001b[0mOverall training speed: 1498 iterations in 0:33:22 (1.3365 s / it)\n",
      "\u001b[32m[12/15 20:53:37 d2.engine.hooks]: \u001b[0mTotal training time: 0:36:15 (0:02:53 on hooks)\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/15 20:53:37 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[12/15 20:53:37 d2.data.datasets.coco]: \u001b[0mLoaded 244 images in COCO format from ../../data/models/detectron2/valid/_annotations.coco.json\n",
      "\u001b[32m[12/15 20:53:37 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/15 20:53:37 d2.data.common]: \u001b[0mSerializing 244 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/15 20:53:37 d2.data.common]: \u001b[0mSerialized dataset takes 0.08 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/15 20:53:37 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[12/15 20:53:37 d2.evaluation.evaluator]: \u001b[0mStart inference on 244 batches\n",
      "\u001b[32m[12/15 20:53:40 d2.evaluation.evaluator]: \u001b[0mInference done 11/244. Dataloading: 0.0004 s/iter. Inference: 0.1562 s/iter. Eval: 0.0003 s/iter. Total: 0.1568 s/iter. ETA=0:00:36\n",
      "\u001b[32m[12/15 20:53:45 d2.evaluation.evaluator]: \u001b[0mInference done 44/244. Dataloading: 0.0004 s/iter. Inference: 0.1543 s/iter. Eval: 0.0003 s/iter. Total: 0.1551 s/iter. ETA=0:00:31\n",
      "\u001b[32m[12/15 20:53:50 d2.evaluation.evaluator]: \u001b[0mInference done 76/244. Dataloading: 0.0004 s/iter. Inference: 0.1569 s/iter. Eval: 0.0003 s/iter. Total: 0.1577 s/iter. ETA=0:00:26\n",
      "\u001b[32m[12/15 20:53:55 d2.evaluation.evaluator]: \u001b[0mInference done 108/244. Dataloading: 0.0004 s/iter. Inference: 0.1567 s/iter. Eval: 0.0003 s/iter. Total: 0.1575 s/iter. ETA=0:00:21\n",
      "\u001b[32m[12/15 20:54:00 d2.evaluation.evaluator]: \u001b[0mInference done 140/244. Dataloading: 0.0004 s/iter. Inference: 0.1567 s/iter. Eval: 0.0003 s/iter. Total: 0.1575 s/iter. ETA=0:00:16\n",
      "\u001b[32m[12/15 20:54:05 d2.evaluation.evaluator]: \u001b[0mInference done 170/244. Dataloading: 0.0004 s/iter. Inference: 0.1586 s/iter. Eval: 0.0003 s/iter. Total: 0.1593 s/iter. ETA=0:00:11\n",
      "\u001b[32m[12/15 20:54:10 d2.evaluation.evaluator]: \u001b[0mInference done 199/244. Dataloading: 0.0004 s/iter. Inference: 0.1610 s/iter. Eval: 0.0003 s/iter. Total: 0.1617 s/iter. ETA=0:00:07\n",
      "\u001b[32m[12/15 20:54:15 d2.evaluation.evaluator]: \u001b[0mInference done 232/244. Dataloading: 0.0004 s/iter. Inference: 0.1599 s/iter. Eval: 0.0003 s/iter. Total: 0.1607 s/iter. ETA=0:00:01\n",
      "\u001b[32m[12/15 20:54:18 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:38.711206 (0.161972 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/15 20:54:18 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:38 (0.160609 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/15 20:54:18 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[12/15 20:54:18 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to coco_eval\\coco_instances_results.json\n",
      "\u001b[32m[12/15 20:54:18 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[12/15 20:54:18 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[12/15 20:54:18 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.04 seconds.\n",
      "\u001b[32m[12/15 20:54:18 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[12/15 20:54:18 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.01 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.247\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.654\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.115\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.245\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.340\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.900\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.213\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.418\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.439\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.435\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.590\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.900\n",
      "\u001b[32m[12/15 20:54:18 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 24.735 | 65.382 | 11.502 | 24.545 | 33.958 | 90.000 |\n",
      "\u001b[32m[12/15 20:54:18 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP   | category   | AP     |\n",
      "|:-----------|:-----|:-----------|:-------|\n",
      "| litter     | nan  | litter     | 24.735 |\n",
      "\u001b[32m[12/15 20:54:18 d2.engine.defaults]: \u001b[0mEvaluation results for data_val in csv format:\n",
      "\u001b[32m[12/15 20:54:18 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[12/15 20:54:18 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[12/15 20:54:18 d2.evaluation.testing]: \u001b[0mcopypaste: 24.7352,65.3821,11.5024,24.5455,33.9575,90.0000\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = CocoTrainer(cfg)\n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 4380), started 0:00:17 ago. (Use '!kill 4380' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-df878ebe40e8d00d\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-df878ebe40e8d00d\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Look at training curves in tensorboard:\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/15 21:10:30 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/15 21:10:30 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[12/15 21:10:30 d2.data.datasets.coco]: \u001b[0mLoaded 122 images in COCO format from ../../data/models/detectron2/test/_annotations.coco.json\n",
      "\u001b[32m[12/15 21:10:30 d2.data.build]: \u001b[0mDistribution of instances among all 2 categories:\n",
      "\u001b[36m|  category  | #instances   |  category  | #instances   |\n",
      "|:----------:|:-------------|:----------:|:-------------|\n",
      "|   litter   | 0            |   litter   | 223          |\n",
      "|            |              |            |              |\n",
      "|   total    | 223          |            |              |\u001b[0m\n",
      "\u001b[32m[12/15 21:10:30 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/15 21:10:30 d2.data.common]: \u001b[0mSerializing 122 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/15 21:10:30 d2.data.common]: \u001b[0mSerialized dataset takes 0.04 MiB\n",
      "\u001b[32m[12/15 21:10:30 d2.evaluation.evaluator]: \u001b[0mStart inference on 122 batches\n",
      "\u001b[32m[12/15 21:10:33 d2.evaluation.evaluator]: \u001b[0mInference done 11/122. Dataloading: 0.0004 s/iter. Inference: 0.1525 s/iter. Eval: 0.0003 s/iter. Total: 0.1531 s/iter. ETA=0:00:16\n",
      "\u001b[32m[12/15 21:10:38 d2.evaluation.evaluator]: \u001b[0mInference done 41/122. Dataloading: 0.0004 s/iter. Inference: 0.1673 s/iter. Eval: 0.0003 s/iter. Total: 0.1681 s/iter. ETA=0:00:13\n",
      "\u001b[32m[12/15 21:10:43 d2.evaluation.evaluator]: \u001b[0mInference done 69/122. Dataloading: 0.0004 s/iter. Inference: 0.1720 s/iter. Eval: 0.0003 s/iter. Total: 0.1728 s/iter. ETA=0:00:09\n",
      "\u001b[32m[12/15 21:10:48 d2.evaluation.evaluator]: \u001b[0mInference done 102/122. Dataloading: 0.0004 s/iter. Inference: 0.1649 s/iter. Eval: 0.0002 s/iter. Total: 0.1656 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/15 21:10:51 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:19.135580 (0.163552 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/15 21:10:51 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:18 (0.161687 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/15 21:10:51 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[12/15 21:10:51 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/coco_instances_results.json\n",
      "\u001b[32m[12/15 21:10:51 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[12/15 21:10:51 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[12/15 21:10:51 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.01 seconds.\n",
      "\u001b[32m[12/15 21:10:51 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[12/15 21:10:51 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.00 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.246\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.700\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.079\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.248\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.270\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.205\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.402\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.415\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.414\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.456\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      "\u001b[32m[12/15 21:10:51 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl  |\n",
      "|:------:|:------:|:------:|:------:|:------:|:-----:|\n",
      "| 24.569 | 70.010 | 7.896  | 24.792 | 27.023 |  nan  |\n",
      "\u001b[32m[12/15 21:10:51 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[12/15 21:10:51 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP   | category   | AP     |\n",
      "|:-----------|:-----|:-----------|:-------|\n",
      "| litter     | nan  | litter     | 24.569 |\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('bbox',\n",
       "              {'AP': 24.56876916790062,\n",
       "               'AP50': 70.01000331210832,\n",
       "               'AP75': 7.896313859938793,\n",
       "               'APs': 24.79158871163907,\n",
       "               'APm': 27.023488134910522,\n",
       "               'APl': nan,\n",
       "               'AP-litter': 24.56876916790062})])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test evaluation\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog, build_detection_test_loader\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.3\n",
    "predictor = DefaultPredictor(cfg)\n",
    "evaluator = COCOEvaluator(\"data_test\", cfg, False, output_dir=\"./output/\")\n",
    "val_loader = build_detection_test_loader(cfg, \"data_test\")\n",
    "inference_on_dataset(trainer.model, val_loader, evaluator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C has no label.\n",
      " Volume Serial Number is 0AE3-82E4\n",
      "\n",
      " Directory of c:\\Users\\Gary Blackwood\\dev\\glasgow-litter\\models\\detectron2\\output\n",
      "\n",
      "15/12/2021  20:53    <DIR>          .\n",
      "15/12/2021  20:53    <DIR>          ..\n",
      "15/12/2021  20:54            66,049 events.out.tfevents.1639599322.Garys-PC.2768.0\n",
      "15/12/2021  20:53                15 last_checkpoint\n",
      "15/12/2021  20:54            42,997 metrics.json\n",
      "15/12/2021  20:53       835,237,695 model_final.pth\n",
      "               4 File(s)    835,346,756 bytes\n",
      "               2 Dir(s)  50,929,061,888 bytes free\n"
     ]
    }
   ],
   "source": [
    "%ls output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.utils.visualizer import ColorMode\n",
    "from IPython.display import Image, display\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import cv2\n",
    "\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
    "cfg.DATASETS.TEST = (\"data_test\", )\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.3   # set the testing threshold for this model\n",
    "predictor = DefaultPredictor(cfg)\n",
    "test_metadata = MetadataCatalog.get(\"data_test\")\n",
    "\n",
    "for imageName in glob.glob('../../data/models/detectron2/test/*jpg')[:10]:\n",
    "  im = cv2.imread(imageName)\n",
    "  outputs = predictor(im)\n",
    "  v = Visualizer(im[:, :, ::-1], metadata=test_metadata)\n",
    "  out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "  img = out.get_image()[:, :, ::-1]\n",
    "  # plt.imshow(img)\n",
    "  cv2.imshow(\"Litter\", img)\n",
    "  cv2.waitKey(0)\n",
    "  cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cf27d97dcf4be97ac4b24b0958c44b40d000600328bb3db0f801b46df5aa5b85"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
