{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "starting_config = \"COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml\"\n",
    "data_dir = \"../../data/models/detectron2/no-augmentations\"\n",
    "output_dir = \"runs/train/no-augmentations\"\n",
    "train_data = \"train_data\"\n",
    "valid_data = \"valid_data\"\n",
    "test_data = \"test_data\"\n",
    "final_model_file = \"model_final.pth\"\n",
    "n_classes = 1\n",
    "batch_size_per_image = 16\n",
    "images_per_batch = 4\n",
    "learning_rate = 0.001\n",
    "warmup_iters = 1000\n",
    "iters = 1500\n",
    "eval_iters = 300\n",
    "steps = [] # (1000, 1500)\n",
    "confidence_threshold = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detectron2 FRCNN Object Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.utils.logger import setup_logger\n",
    "\n",
    "setup_logger()\n",
    "\n",
    "register_coco_instances(train_data, {}, f\"{data_dir}/train/_annotations.coco.json\", f\"{data_dir}/train\")\n",
    "register_coco_instances(valid_data, {}, f\"{data_dir}/valid/_annotations.coco.json\", f\"{data_dir}/valid\")\n",
    "register_coco_instances(test_data, {}, f\"{data_dir}/test/_annotations.coco.json\", f\"{data_dir}/test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[01/02 15:48:13 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (6): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (7): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (8): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (9): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (10): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (11): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (12): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (13): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (14): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (15): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (16): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (17): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (18): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (19): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (20): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (21): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (22): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[01/02 15:48:13 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[01/02 15:48:13 d2.data.datasets.coco]: \u001b[0mLoaded 823 images in COCO format from ../../data/models/detectron2/no-augmentations/train/_annotations.coco.json\n",
      "\u001b[32m[01/02 15:48:13 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 823 images left.\n",
      "\u001b[32m[01/02 15:48:13 d2.data.build]: \u001b[0mDistribution of instances among all 2 categories:\n",
      "\u001b[36m|  category  | #instances   |  category  | #instances   |\n",
      "|:----------:|:-------------|:----------:|:-------------|\n",
      "|   litter   | 0            |   litter   | 1520         |\n",
      "|            |              |            |              |\n",
      "|   total    | 1520         |            |              |\u001b[0m\n",
      "\u001b[32m[01/02 15:48:13 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[01/02 15:48:13 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[01/02 15:48:13 d2.data.common]: \u001b[0mSerializing 823 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/02 15:48:13 d2.data.common]: \u001b[0mSerialized dataset takes 0.29 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (2, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (2,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[01/02 15:48:14 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gary Blackwood\\dev\\glasgow-litter\\venv\\lib\\site-packages\\torch\\functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ..\\aten\\src\\ATen\\native\\TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[01/02 15:48:45 d2.utils.events]: \u001b[0m eta: 0:33:51  iter: 19  total_loss: 1.559  loss_cls: 0.7676  loss_box_reg: 0  loss_rpn_cls: 0.7577  loss_rpn_loc: 0.06598  time: 1.3440  data_time: 0.1071  lr: 1.9981e-05  max_mem: 7206M\n",
      "\u001b[32m[01/02 15:49:13 d2.utils.events]: \u001b[0m eta: 0:33:53  iter: 39  total_loss: 0.7917  loss_cls: 0.4258  loss_box_reg: 0  loss_rpn_cls: 0.2436  loss_rpn_loc: 0.0771  time: 1.3770  data_time: 0.0369  lr: 3.9961e-05  max_mem: 7206M\n",
      "\u001b[32m[01/02 15:49:41 d2.utils.events]: \u001b[0m eta: 0:34:21  iter: 59  total_loss: 0.263  loss_cls: 0.1765  loss_box_reg: 0  loss_rpn_cls: 0.04035  loss_rpn_loc: 0.04779  time: 1.3944  data_time: 0.0377  lr: 5.9941e-05  max_mem: 7206M\n",
      "\u001b[32m[01/02 15:50:11 d2.utils.events]: \u001b[0m eta: 0:34:03  iter: 79  total_loss: 0.1692  loss_cls: 0.07135  loss_box_reg: 0  loss_rpn_cls: 0.04229  loss_rpn_loc: 0.05305  time: 1.4149  data_time: 0.0374  lr: 7.9921e-05  max_mem: 7206M\n",
      "\u001b[32m[01/02 15:50:41 d2.utils.events]: \u001b[0m eta: 0:33:39  iter: 99  total_loss: 0.1164  loss_cls: 0.03014  loss_box_reg: 0  loss_rpn_cls: 0.03109  loss_rpn_loc: 0.05394  time: 1.4281  data_time: 0.0384  lr: 9.9901e-05  max_mem: 7206M\n",
      "\u001b[32m[01/02 15:51:10 d2.utils.events]: \u001b[0m eta: 0:33:13  iter: 119  total_loss: 0.09204  loss_cls: 0.0186  loss_box_reg: 0  loss_rpn_cls: 0.02991  loss_rpn_loc: 0.04158  time: 1.4351  data_time: 0.0375  lr: 0.00011988  max_mem: 7206M\n",
      "\u001b[32m[01/02 15:51:40 d2.utils.events]: \u001b[0m eta: 0:32:47  iter: 139  total_loss: 0.1099  loss_cls: 0.01257  loss_box_reg: 0  loss_rpn_cls: 0.03957  loss_rpn_loc: 0.05272  time: 1.4452  data_time: 0.0395  lr: 0.00013986  max_mem: 7206M\n",
      "\u001b[32m[01/02 15:52:11 d2.utils.events]: \u001b[0m eta: 0:32:21  iter: 159  total_loss: 0.06642  loss_cls: 0.008903  loss_box_reg: 0  loss_rpn_cls: 0.02684  loss_rpn_loc: 0.03988  time: 1.4549  data_time: 0.0382  lr: 0.00015984  max_mem: 7206M\n",
      "\u001b[32m[01/02 15:52:40 d2.utils.events]: \u001b[0m eta: 0:31:52  iter: 179  total_loss: 0.08479  loss_cls: 0.006113  loss_box_reg: 0  loss_rpn_cls: 0.034  loss_rpn_loc: 0.03735  time: 1.4552  data_time: 0.0380  lr: 0.00017982  max_mem: 7206M\n",
      "\u001b[32m[01/02 15:53:08 d2.utils.events]: \u001b[0m eta: 0:31:24  iter: 199  total_loss: 0.0693  loss_cls: 0.004686  loss_box_reg: 0  loss_rpn_cls: 0.01915  loss_rpn_loc: 0.04506  time: 1.4522  data_time: 0.0379  lr: 0.0001998  max_mem: 7206M\n",
      "\u001b[32m[01/02 15:53:37 d2.utils.events]: \u001b[0m eta: 0:30:55  iter: 219  total_loss: 0.07232  loss_cls: 0.003123  loss_box_reg: 0  loss_rpn_cls: 0.02198  loss_rpn_loc: 0.04185  time: 1.4495  data_time: 0.0334  lr: 0.00021978  max_mem: 7206M\n",
      "\u001b[32m[01/02 15:54:06 d2.utils.events]: \u001b[0m eta: 0:30:32  iter: 239  total_loss: 0.06914  loss_cls: 0.003088  loss_box_reg: 0  loss_rpn_cls: 0.01594  loss_rpn_loc: 0.05148  time: 1.4498  data_time: 0.0307  lr: 0.00023976  max_mem: 7206M\n",
      "\u001b[32m[01/02 15:54:35 d2.utils.events]: \u001b[0m eta: 0:29:57  iter: 259  total_loss: 0.08287  loss_cls: 0.003252  loss_box_reg: 0  loss_rpn_cls: 0.02082  loss_rpn_loc: 0.05775  time: 1.4505  data_time: 0.0312  lr: 0.00025974  max_mem: 7206M\n",
      "\u001b[32m[01/02 15:55:04 d2.utils.events]: \u001b[0m eta: 0:29:40  iter: 279  total_loss: 0.0731  loss_cls: 0.002341  loss_box_reg: 0  loss_rpn_cls: 0.01927  loss_rpn_loc: 0.04645  time: 1.4507  data_time: 0.0307  lr: 0.00027972  max_mem: 7206M\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[01/02 15:55:33 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[01/02 15:55:33 d2.data.datasets.coco]: \u001b[0mLoaded 237 images in COCO format from ../../data/models/detectron2/no-augmentations/valid/_annotations.coco.json\n",
      "\u001b[32m[01/02 15:55:33 d2.data.build]: \u001b[0mDistribution of instances among all 2 categories:\n",
      "\u001b[36m|  category  | #instances   |  category  | #instances   |\n",
      "|:----------:|:-------------|:----------:|:-------------|\n",
      "|   litter   | 0            |   litter   | 464          |\n",
      "|            |              |            |              |\n",
      "|   total    | 464          |            |              |\u001b[0m\n",
      "\u001b[32m[01/02 15:55:33 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/02 15:55:33 d2.data.common]: \u001b[0mSerializing 237 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/02 15:55:33 d2.data.common]: \u001b[0mSerialized dataset takes 0.08 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[01/02 15:55:33 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[01/02 15:55:33 d2.evaluation.evaluator]: \u001b[0mStart inference on 237 batches\n",
      "\u001b[32m[01/02 15:55:36 d2.evaluation.evaluator]: \u001b[0mInference done 11/237. Dataloading: 0.0003 s/iter. Inference: 0.1826 s/iter. Eval: 0.0001 s/iter. Total: 0.1830 s/iter. ETA=0:00:41\n",
      "\u001b[32m[01/02 15:55:41 d2.evaluation.evaluator]: \u001b[0mInference done 39/237. Dataloading: 0.0004 s/iter. Inference: 0.1827 s/iter. Eval: 0.0001 s/iter. Total: 0.1832 s/iter. ETA=0:00:36\n",
      "\u001b[32m[01/02 15:55:46 d2.evaluation.evaluator]: \u001b[0mInference done 67/237. Dataloading: 0.0004 s/iter. Inference: 0.1827 s/iter. Eval: 0.0001 s/iter. Total: 0.1832 s/iter. ETA=0:00:31\n",
      "\u001b[32m[01/02 15:55:51 d2.evaluation.evaluator]: \u001b[0mInference done 95/237. Dataloading: 0.0004 s/iter. Inference: 0.1826 s/iter. Eval: 0.0001 s/iter. Total: 0.1832 s/iter. ETA=0:00:26\n",
      "\u001b[32m[01/02 15:55:56 d2.evaluation.evaluator]: \u001b[0mInference done 123/237. Dataloading: 0.0004 s/iter. Inference: 0.1827 s/iter. Eval: 0.0001 s/iter. Total: 0.1832 s/iter. ETA=0:00:20\n",
      "\u001b[32m[01/02 15:56:01 d2.evaluation.evaluator]: \u001b[0mInference done 151/237. Dataloading: 0.0004 s/iter. Inference: 0.1828 s/iter. Eval: 0.0001 s/iter. Total: 0.1833 s/iter. ETA=0:00:15\n",
      "\u001b[32m[01/02 15:56:07 d2.evaluation.evaluator]: \u001b[0mInference done 179/237. Dataloading: 0.0004 s/iter. Inference: 0.1828 s/iter. Eval: 0.0001 s/iter. Total: 0.1833 s/iter. ETA=0:00:10\n",
      "\u001b[32m[01/02 15:56:12 d2.evaluation.evaluator]: \u001b[0mInference done 207/237. Dataloading: 0.0004 s/iter. Inference: 0.1828 s/iter. Eval: 0.0001 s/iter. Total: 0.1833 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/02 15:56:17 d2.evaluation.evaluator]: \u001b[0mInference done 235/237. Dataloading: 0.0004 s/iter. Inference: 0.1828 s/iter. Eval: 0.0001 s/iter. Total: 0.1834 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/02 15:56:17 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:42.657157 (0.183867 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/02 15:56:17 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:42 (0.182808 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/02 15:56:17 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[01/02 15:56:17 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to runs/train/no-augmentations\\coco_instances_results.json\n",
      "\u001b[32m[01/02 15:56:17 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[01/02 15:56:17 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[01/02 15:56:17 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.01 seconds.\n",
      "\u001b[32m[01/02 15:56:17 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[01/02 15:56:17 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.00 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      "\u001b[32m[01/02 15:56:17 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| 0.000 | 0.000  | 0.000  | 0.000 | 0.000 | 0.000 |\n",
      "\u001b[32m[01/02 15:56:17 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP   | category   | AP    |\n",
      "|:-----------|:-----|:-----------|:------|\n",
      "| litter     | nan  | litter     | 0.000 |\n",
      "\u001b[32m[01/02 15:56:17 d2.engine.defaults]: \u001b[0mEvaluation results for valid_data in csv format:\n",
      "\u001b[32m[01/02 15:56:17 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[01/02 15:56:17 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[01/02 15:56:17 d2.evaluation.testing]: \u001b[0mcopypaste: 0.0000,0.0000,0.0000,0.0000,0.0000,0.0000\n",
      "\u001b[32m[01/02 15:56:17 d2.utils.events]: \u001b[0m eta: 0:29:00  iter: 299  total_loss: 0.06712  loss_cls: 0.001596  loss_box_reg: 0  loss_rpn_cls: 0.02037  loss_rpn_loc: 0.03852  time: 1.4491  data_time: 0.0303  lr: 0.0002997  max_mem: 7206M\n",
      "\u001b[32m[01/02 15:56:47 d2.utils.events]: \u001b[0m eta: 0:28:36  iter: 319  total_loss: 0.0716  loss_cls: 0.002139  loss_box_reg: 0  loss_rpn_cls: 0.01941  loss_rpn_loc: 0.04614  time: 1.4497  data_time: 0.0308  lr: 0.00031968  max_mem: 7206M\n",
      "\u001b[32m[01/02 15:57:16 d2.utils.events]: \u001b[0m eta: 0:28:02  iter: 339  total_loss: 0.06257  loss_cls: 0.001808  loss_box_reg: 0  loss_rpn_cls: 0.01729  loss_rpn_loc: 0.03907  time: 1.4495  data_time: 0.0303  lr: 0.00033966  max_mem: 7206M\n",
      "\u001b[32m[01/02 15:57:45 d2.utils.events]: \u001b[0m eta: 0:27:44  iter: 359  total_loss: 0.05883  loss_cls: 0.001765  loss_box_reg: 0  loss_rpn_cls: 0.01716  loss_rpn_loc: 0.04224  time: 1.4512  data_time: 0.0314  lr: 0.00035964  max_mem: 7206M\n",
      "\u001b[32m[01/02 15:58:14 d2.utils.events]: \u001b[0m eta: 0:27:13  iter: 379  total_loss: 0.06468  loss_cls: 0.001014  loss_box_reg: 0  loss_rpn_cls: 0.01546  loss_rpn_loc: 0.04608  time: 1.4518  data_time: 0.0315  lr: 0.00037962  max_mem: 7206M\n",
      "\u001b[32m[01/02 15:58:44 d2.utils.events]: \u001b[0m eta: 0:26:45  iter: 399  total_loss: 0.05857  loss_cls: 0.001242  loss_box_reg: 0  loss_rpn_cls: 0.01278  loss_rpn_loc: 0.04471  time: 1.4530  data_time: 0.0313  lr: 0.0003996  max_mem: 7206M\n",
      "\u001b[32m[01/02 15:59:13 d2.utils.events]: \u001b[0m eta: 0:26:20  iter: 419  total_loss: 0.05809  loss_cls: 0.001139  loss_box_reg: 0  loss_rpn_cls: 0.01488  loss_rpn_loc: 0.0319  time: 1.4539  data_time: 0.0300  lr: 0.00041958  max_mem: 7206M\n",
      "\u001b[32m[01/02 15:59:43 d2.utils.events]: \u001b[0m eta: 0:25:50  iter: 439  total_loss: 0.05974  loss_cls: 0.000696  loss_box_reg: 0  loss_rpn_cls: 0.01379  loss_rpn_loc: 0.04309  time: 1.4544  data_time: 0.0309  lr: 0.00043956  max_mem: 7206M\n",
      "\u001b[32m[01/02 16:00:11 d2.utils.events]: \u001b[0m eta: 0:25:21  iter: 459  total_loss: 0.0505  loss_cls: 0.0007852  loss_box_reg: 0  loss_rpn_cls: 0.01214  loss_rpn_loc: 0.03755  time: 1.4535  data_time: 0.0310  lr: 0.00045954  max_mem: 7206M\n",
      "\u001b[32m[01/02 16:00:41 d2.utils.events]: \u001b[0m eta: 0:24:52  iter: 479  total_loss: 0.06031  loss_cls: 0.0007674  loss_box_reg: 0  loss_rpn_cls: 0.01323  loss_rpn_loc: 0.0445  time: 1.4541  data_time: 0.0323  lr: 0.00047952  max_mem: 7206M\n",
      "\u001b[32m[01/02 16:01:10 d2.utils.events]: \u001b[0m eta: 0:24:42  iter: 499  total_loss: 0.05291  loss_cls: 0.0005898  loss_box_reg: 0  loss_rpn_cls: 0.01532  loss_rpn_loc: 0.03886  time: 1.4549  data_time: 0.0308  lr: 0.0004995  max_mem: 7206M\n",
      "\u001b[32m[01/02 16:01:39 d2.utils.events]: \u001b[0m eta: 0:24:13  iter: 519  total_loss: 0.04411  loss_cls: 0.0004918  loss_box_reg: 0  loss_rpn_cls: 0.01321  loss_rpn_loc: 0.03428  time: 1.4548  data_time: 0.0311  lr: 0.00051948  max_mem: 7206M\n",
      "\u001b[32m[01/02 16:02:09 d2.utils.events]: \u001b[0m eta: 0:23:50  iter: 539  total_loss: 0.06925  loss_cls: 0.0005758  loss_box_reg: 0  loss_rpn_cls: 0.01734  loss_rpn_loc: 0.04931  time: 1.4557  data_time: 0.0309  lr: 0.00053946  max_mem: 7206M\n",
      "\u001b[32m[01/02 16:02:38 d2.utils.events]: \u001b[0m eta: 0:23:20  iter: 559  total_loss: 0.05583  loss_cls: 0.0004275  loss_box_reg: 0  loss_rpn_cls: 0.01196  loss_rpn_loc: 0.04644  time: 1.4556  data_time: 0.0307  lr: 0.00055944  max_mem: 7206M\n",
      "\u001b[32m[01/02 16:03:06 d2.utils.events]: \u001b[0m eta: 0:22:25  iter: 579  total_loss: 0.05984  loss_cls: 0.0004041  loss_box_reg: 0  loss_rpn_cls: 0.01245  loss_rpn_loc: 0.05147  time: 1.4529  data_time: 0.0301  lr: 0.00057942  max_mem: 7206M\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[01/02 16:03:35 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[01/02 16:03:35 d2.data.datasets.coco]: \u001b[0mLoaded 237 images in COCO format from ../../data/models/detectron2/no-augmentations/valid/_annotations.coco.json\n",
      "\u001b[32m[01/02 16:03:35 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/02 16:03:35 d2.data.common]: \u001b[0mSerializing 237 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/02 16:03:35 d2.data.common]: \u001b[0mSerialized dataset takes 0.08 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[01/02 16:03:35 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[01/02 16:03:35 d2.evaluation.evaluator]: \u001b[0mStart inference on 237 batches\n",
      "\u001b[32m[01/02 16:03:38 d2.evaluation.evaluator]: \u001b[0mInference done 11/237. Dataloading: 0.0003 s/iter. Inference: 0.1822 s/iter. Eval: 0.0000 s/iter. Total: 0.1826 s/iter. ETA=0:00:41\n",
      "\u001b[32m[01/02 16:03:43 d2.evaluation.evaluator]: \u001b[0mInference done 39/237. Dataloading: 0.0004 s/iter. Inference: 0.1824 s/iter. Eval: 0.0001 s/iter. Total: 0.1829 s/iter. ETA=0:00:36\n",
      "\u001b[32m[01/02 16:03:48 d2.evaluation.evaluator]: \u001b[0mInference done 67/237. Dataloading: 0.0004 s/iter. Inference: 0.1827 s/iter. Eval: 0.0001 s/iter. Total: 0.1832 s/iter. ETA=0:00:31\n",
      "\u001b[32m[01/02 16:03:54 d2.evaluation.evaluator]: \u001b[0mInference done 95/237. Dataloading: 0.0004 s/iter. Inference: 0.1826 s/iter. Eval: 0.0001 s/iter. Total: 0.1830 s/iter. ETA=0:00:25\n",
      "\u001b[32m[01/02 16:03:59 d2.evaluation.evaluator]: \u001b[0mInference done 123/237. Dataloading: 0.0004 s/iter. Inference: 0.1824 s/iter. Eval: 0.0001 s/iter. Total: 0.1828 s/iter. ETA=0:00:20\n",
      "\u001b[32m[01/02 16:04:04 d2.evaluation.evaluator]: \u001b[0mInference done 151/237. Dataloading: 0.0004 s/iter. Inference: 0.1823 s/iter. Eval: 0.0001 s/iter. Total: 0.1828 s/iter. ETA=0:00:15\n",
      "\u001b[32m[01/02 16:04:09 d2.evaluation.evaluator]: \u001b[0mInference done 179/237. Dataloading: 0.0004 s/iter. Inference: 0.1824 s/iter. Eval: 0.0001 s/iter. Total: 0.1828 s/iter. ETA=0:00:10\n",
      "\u001b[32m[01/02 16:04:14 d2.evaluation.evaluator]: \u001b[0mInference done 207/237. Dataloading: 0.0004 s/iter. Inference: 0.1823 s/iter. Eval: 0.0001 s/iter. Total: 0.1828 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/02 16:04:19 d2.evaluation.evaluator]: \u001b[0mInference done 235/237. Dataloading: 0.0004 s/iter. Inference: 0.1824 s/iter. Eval: 0.0001 s/iter. Total: 0.1828 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/02 16:04:20 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:42.543170 (0.183376 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/02 16:04:20 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:42 (0.182362 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/02 16:04:20 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[01/02 16:04:20 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to runs/train/no-augmentations\\coco_instances_results.json\n",
      "\u001b[32m[01/02 16:04:20 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[01/02 16:04:20 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[01/02 16:04:20 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.01 seconds.\n",
      "\u001b[32m[01/02 16:04:20 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[01/02 16:04:20 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.00 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      "\u001b[32m[01/02 16:04:20 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| 0.000 | 0.000  | 0.000  | 0.000 | 0.000 | 0.000 |\n",
      "\u001b[32m[01/02 16:04:20 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP   | category   | AP    |\n",
      "|:-----------|:-----|:-----------|:------|\n",
      "| litter     | nan  | litter     | 0.000 |\n",
      "\u001b[32m[01/02 16:04:20 d2.engine.defaults]: \u001b[0mEvaluation results for valid_data in csv format:\n",
      "\u001b[32m[01/02 16:04:20 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[01/02 16:04:20 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[01/02 16:04:20 d2.evaluation.testing]: \u001b[0mcopypaste: 0.0000,0.0000,0.0000,0.0000,0.0000,0.0000\n",
      "\u001b[32m[01/02 16:04:20 d2.utils.events]: \u001b[0m eta: 0:22:00  iter: 599  total_loss: 0.06339  loss_cls: 0.0003959  loss_box_reg: 0  loss_rpn_cls: 0.01396  loss_rpn_loc: 0.05069  time: 1.4536  data_time: 0.0314  lr: 0.0005994  max_mem: 7206M\n",
      "\u001b[32m[01/02 16:04:49 d2.utils.events]: \u001b[0m eta: 0:21:27  iter: 619  total_loss: 0.04545  loss_cls: 0.0003537  loss_box_reg: 0  loss_rpn_cls: 0.01042  loss_rpn_loc: 0.03645  time: 1.4533  data_time: 0.0307  lr: 0.00061938  max_mem: 7206M\n",
      "\u001b[32m[01/02 16:05:17 d2.utils.events]: \u001b[0m eta: 0:20:58  iter: 639  total_loss: 0.04635  loss_cls: 0.0003844  loss_box_reg: 0  loss_rpn_cls: 0.009221  loss_rpn_loc: 0.0374  time: 1.4524  data_time: 0.0319  lr: 0.00063936  max_mem: 7206M\n",
      "\u001b[32m[01/02 16:05:46 d2.utils.events]: \u001b[0m eta: 0:20:28  iter: 659  total_loss: 0.04867  loss_cls: 0.0002857  loss_box_reg: 0  loss_rpn_cls: 0.009514  loss_rpn_loc: 0.03434  time: 1.4525  data_time: 0.0322  lr: 0.00065934  max_mem: 7206M\n",
      "\u001b[32m[01/02 16:06:15 d2.utils.events]: \u001b[0m eta: 0:19:57  iter: 679  total_loss: 0.05481  loss_cls: 0.0003539  loss_box_reg: 0  loss_rpn_cls: 0.01169  loss_rpn_loc: 0.04006  time: 1.4522  data_time: 0.0309  lr: 0.00067932  max_mem: 7206M\n",
      "\u001b[32m[01/02 16:06:44 d2.utils.events]: \u001b[0m eta: 0:19:27  iter: 699  total_loss: 0.04851  loss_cls: 0.0002545  loss_box_reg: 0  loss_rpn_cls: 0.009538  loss_rpn_loc: 0.03556  time: 1.4526  data_time: 0.0312  lr: 0.0006993  max_mem: 7206M\n",
      "\u001b[32m[01/02 16:07:14 d2.utils.events]: \u001b[0m eta: 0:18:58  iter: 719  total_loss: 0.04692  loss_cls: 0.0002123  loss_box_reg: 0  loss_rpn_cls: 0.01028  loss_rpn_loc: 0.03386  time: 1.4528  data_time: 0.0317  lr: 0.00071928  max_mem: 7206M\n",
      "\u001b[32m[01/02 16:07:43 d2.utils.events]: \u001b[0m eta: 0:18:37  iter: 739  total_loss: 0.05076  loss_cls: 0.00025  loss_box_reg: 0  loss_rpn_cls: 0.01127  loss_rpn_loc: 0.0334  time: 1.4537  data_time: 0.0311  lr: 0.00073926  max_mem: 7206M\n",
      "\u001b[32m[01/02 16:08:13 d2.utils.events]: \u001b[0m eta: 0:18:16  iter: 759  total_loss: 0.06182  loss_cls: 0.0001539  loss_box_reg: 0  loss_rpn_cls: 0.009611  loss_rpn_loc: 0.05217  time: 1.4539  data_time: 0.0305  lr: 0.00075924  max_mem: 7206M\n",
      "\u001b[32m[01/02 16:08:41 d2.utils.events]: \u001b[0m eta: 0:17:36  iter: 779  total_loss: 0.03899  loss_cls: 0.0002409  loss_box_reg: 0  loss_rpn_cls: 0.007515  loss_rpn_loc: 0.03207  time: 1.4535  data_time: 0.0312  lr: 0.00077922  max_mem: 7206M\n",
      "\u001b[32m[01/02 16:09:11 d2.utils.events]: \u001b[0m eta: 0:17:17  iter: 799  total_loss: 0.0893  loss_cls: 0.0001585  loss_box_reg: 0  loss_rpn_cls: 0.01171  loss_rpn_loc: 0.06855  time: 1.4544  data_time: 0.0308  lr: 0.0007992  max_mem: 7206M\n",
      "\u001b[32m[01/02 16:09:40 d2.utils.events]: \u001b[0m eta: 0:16:48  iter: 819  total_loss: 0.05341  loss_cls: 0.0001371  loss_box_reg: 0  loss_rpn_cls: 0.0104  loss_rpn_loc: 0.04283  time: 1.4544  data_time: 0.0310  lr: 0.00081918  max_mem: 7206M\n",
      "\u001b[32m[01/02 16:10:10 d2.utils.events]: \u001b[0m eta: 0:16:19  iter: 839  total_loss: 0.0432  loss_cls: 0.000216  loss_box_reg: 0  loss_rpn_cls: 0.01167  loss_rpn_loc: 0.03592  time: 1.4548  data_time: 0.0311  lr: 0.00083916  max_mem: 7206M\n",
      "\u001b[32m[01/02 16:10:39 d2.utils.events]: \u001b[0m eta: 0:15:50  iter: 859  total_loss: 0.04513  loss_cls: 0.0001745  loss_box_reg: 0  loss_rpn_cls: 0.01145  loss_rpn_loc: 0.03449  time: 1.4545  data_time: 0.0305  lr: 0.00085914  max_mem: 7206M\n",
      "\u001b[32m[01/02 16:11:07 d2.utils.events]: \u001b[0m eta: 0:15:19  iter: 879  total_loss: 0.05477  loss_cls: 0.0002488  loss_box_reg: 0  loss_rpn_cls: 0.01053  loss_rpn_loc: 0.04309  time: 1.4537  data_time: 0.0302  lr: 0.00087912  max_mem: 7206M\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[01/02 16:11:33 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[01/02 16:11:33 d2.data.datasets.coco]: \u001b[0mLoaded 237 images in COCO format from ../../data/models/detectron2/no-augmentations/valid/_annotations.coco.json\n",
      "\u001b[32m[01/02 16:11:33 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/02 16:11:33 d2.data.common]: \u001b[0mSerializing 237 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/02 16:11:33 d2.data.common]: \u001b[0mSerialized dataset takes 0.08 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[01/02 16:11:33 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[01/02 16:11:33 d2.evaluation.evaluator]: \u001b[0mStart inference on 237 batches\n",
      "\u001b[32m[01/02 16:11:37 d2.evaluation.evaluator]: \u001b[0mInference done 11/237. Dataloading: 0.0003 s/iter. Inference: 0.1825 s/iter. Eval: 0.0000 s/iter. Total: 0.1829 s/iter. ETA=0:00:41\n",
      "\u001b[32m[01/02 16:11:42 d2.evaluation.evaluator]: \u001b[0mInference done 38/237. Dataloading: 0.0004 s/iter. Inference: 0.1867 s/iter. Eval: 0.0001 s/iter. Total: 0.1872 s/iter. ETA=0:00:37\n",
      "\u001b[32m[01/02 16:11:47 d2.evaluation.evaluator]: \u001b[0mInference done 67/237. Dataloading: 0.0004 s/iter. Inference: 0.1823 s/iter. Eval: 0.0001 s/iter. Total: 0.1828 s/iter. ETA=0:00:31\n",
      "\u001b[32m[01/02 16:11:52 d2.evaluation.evaluator]: \u001b[0mInference done 98/237. Dataloading: 0.0004 s/iter. Inference: 0.1758 s/iter. Eval: 0.0001 s/iter. Total: 0.1762 s/iter. ETA=0:00:24\n",
      "\u001b[32m[01/02 16:11:57 d2.evaluation.evaluator]: \u001b[0mInference done 130/237. Dataloading: 0.0004 s/iter. Inference: 0.1718 s/iter. Eval: 0.0000 s/iter. Total: 0.1722 s/iter. ETA=0:00:18\n",
      "\u001b[32m[01/02 16:12:02 d2.evaluation.evaluator]: \u001b[0mInference done 162/237. Dataloading: 0.0004 s/iter. Inference: 0.1694 s/iter. Eval: 0.0000 s/iter. Total: 0.1699 s/iter. ETA=0:00:12\n",
      "\u001b[32m[01/02 16:12:07 d2.evaluation.evaluator]: \u001b[0mInference done 193/237. Dataloading: 0.0004 s/iter. Inference: 0.1680 s/iter. Eval: 0.0000 s/iter. Total: 0.1685 s/iter. ETA=0:00:07\n",
      "\u001b[32m[01/02 16:12:12 d2.evaluation.evaluator]: \u001b[0mInference done 223/237. Dataloading: 0.0004 s/iter. Inference: 0.1678 s/iter. Eval: 0.0000 s/iter. Total: 0.1682 s/iter. ETA=0:00:02\n",
      "\u001b[32m[01/02 16:12:15 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:39.078617 (0.168442 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/02 16:12:15 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:38 (0.167442 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/02 16:12:15 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[01/02 16:12:15 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to runs/train/no-augmentations\\coco_instances_results.json\n",
      "\u001b[32m[01/02 16:12:15 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[01/02 16:12:15 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[01/02 16:12:15 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.01 seconds.\n",
      "\u001b[32m[01/02 16:12:15 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[01/02 16:12:15 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.00 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      "\u001b[32m[01/02 16:12:15 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| 0.000 | 0.000  | 0.000  | 0.000 | 0.000 | 0.000 |\n",
      "\u001b[32m[01/02 16:12:15 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP   | category   | AP    |\n",
      "|:-----------|:-----|:-----------|:------|\n",
      "| litter     | nan  | litter     | 0.000 |\n",
      "\u001b[32m[01/02 16:12:15 d2.engine.defaults]: \u001b[0mEvaluation results for valid_data in csv format:\n",
      "\u001b[32m[01/02 16:12:15 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[01/02 16:12:15 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[01/02 16:12:15 d2.evaluation.testing]: \u001b[0mcopypaste: 0.0000,0.0000,0.0000,0.0000,0.0000,0.0000\n",
      "\u001b[32m[01/02 16:12:15 d2.utils.events]: \u001b[0m eta: 0:14:32  iter: 899  total_loss: 0.04699  loss_cls: 0.000144  loss_box_reg: 0  loss_rpn_cls: 0.009292  loss_rpn_loc: 0.04189  time: 1.4507  data_time: 0.0305  lr: 0.0008991  max_mem: 7206M\n",
      "\u001b[32m[01/02 16:12:40 d2.utils.events]: \u001b[0m eta: 0:13:59  iter: 919  total_loss: 0.05484  loss_cls: 0.0001111  loss_box_reg: 0  loss_rpn_cls: 0.008313  loss_rpn_loc: 0.04885  time: 1.4471  data_time: 0.0303  lr: 0.00091908  max_mem: 7206M\n",
      "\u001b[32m[01/02 16:13:43 d2.utils.events]: \u001b[0m eta: 0:13:31  iter: 939  total_loss: 0.05537  loss_cls: 0.0001185  loss_box_reg: 0  loss_rpn_cls: 0.009161  loss_rpn_loc: 0.04727  time: 1.4829  data_time: 0.0316  lr: 0.00093906  max_mem: 7206M\n",
      "\u001b[32m[01/02 16:14:09 d2.utils.events]: \u001b[0m eta: 0:13:00  iter: 959  total_loss: 0.05722  loss_cls: 0.0001775  loss_box_reg: 0  loss_rpn_cls: 0.008253  loss_rpn_loc: 0.04571  time: 1.4793  data_time: 0.0315  lr: 0.00095904  max_mem: 7206M\n",
      "\u001b[32m[01/02 16:14:35 d2.utils.events]: \u001b[0m eta: 0:12:30  iter: 979  total_loss: 0.04063  loss_cls: 0.0001124  loss_box_reg: 0  loss_rpn_cls: 0.006281  loss_rpn_loc: 0.03361  time: 1.4759  data_time: 0.0304  lr: 0.00097902  max_mem: 7206M\n",
      "\u001b[32m[01/02 16:15:01 d2.utils.events]: \u001b[0m eta: 0:11:59  iter: 999  total_loss: 0.06103  loss_cls: 0.0001023  loss_box_reg: 0  loss_rpn_cls: 0.008828  loss_rpn_loc: 0.04977  time: 1.4721  data_time: 0.0305  lr: 0.000999  max_mem: 7206M\n",
      "\u001b[32m[01/02 16:15:27 d2.utils.events]: \u001b[0m eta: 0:11:30  iter: 1019  total_loss: 0.05305  loss_cls: 0.0001223  loss_box_reg: 0  loss_rpn_cls: 0.009377  loss_rpn_loc: 0.04257  time: 1.4689  data_time: 0.0311  lr: 0.001  max_mem: 7206M\n",
      "\u001b[32m[01/02 16:15:56 d2.utils.events]: \u001b[0m eta: 0:11:01  iter: 1039  total_loss: 0.05151  loss_cls: 8.898e-05  loss_box_reg: 0  loss_rpn_cls: 0.008086  loss_rpn_loc: 0.0474  time: 1.4678  data_time: 0.0321  lr: 0.001  max_mem: 7206M\n",
      "\u001b[32m[01/02 16:16:31 d2.utils.events]: \u001b[0m eta: 0:10:32  iter: 1059  total_loss: 0.0436  loss_cls: 0.0001051  loss_box_reg: 0  loss_rpn_cls: 0.00712  loss_rpn_loc: 0.03743  time: 1.4739  data_time: 0.0312  lr: 0.001  max_mem: 7206M\n",
      "\u001b[32m[01/02 16:16:59 d2.utils.events]: \u001b[0m eta: 0:10:03  iter: 1079  total_loss: 0.04414  loss_cls: 0.0001192  loss_box_reg: 0  loss_rpn_cls: 0.005394  loss_rpn_loc: 0.03886  time: 1.4723  data_time: 0.0314  lr: 0.001  max_mem: 7206M\n",
      "\u001b[32m[01/02 16:17:24 d2.utils.events]: \u001b[0m eta: 0:09:33  iter: 1099  total_loss: 0.05605  loss_cls: 0.0001078  loss_box_reg: 0  loss_rpn_cls: 0.01036  loss_rpn_loc: 0.04565  time: 1.4684  data_time: 0.0310  lr: 0.001  max_mem: 7206M\n",
      "\u001b[32m[01/02 16:17:52 d2.utils.events]: \u001b[0m eta: 0:09:04  iter: 1119  total_loss: 0.04438  loss_cls: 8.858e-05  loss_box_reg: 0  loss_rpn_cls: 0.007218  loss_rpn_loc: 0.03569  time: 1.4667  data_time: 0.0308  lr: 0.001  max_mem: 7206M\n",
      "\u001b[32m[01/02 16:18:19 d2.utils.events]: \u001b[0m eta: 0:08:35  iter: 1139  total_loss: 0.05753  loss_cls: 8.165e-05  loss_box_reg: 0  loss_rpn_cls: 0.00852  loss_rpn_loc: 0.04843  time: 1.4650  data_time: 0.0308  lr: 0.001  max_mem: 7206M\n",
      "\u001b[32m[01/02 16:18:46 d2.utils.events]: \u001b[0m eta: 0:08:06  iter: 1159  total_loss: 0.04968  loss_cls: 8.168e-05  loss_box_reg: 0  loss_rpn_cls: 0.006381  loss_rpn_loc: 0.04073  time: 1.4623  data_time: 0.0318  lr: 0.001  max_mem: 7206M\n",
      "\u001b[32m[01/02 16:19:14 d2.utils.events]: \u001b[0m eta: 0:07:38  iter: 1179  total_loss: 0.05132  loss_cls: 7.053e-05  loss_box_reg: 0  loss_rpn_cls: 0.006859  loss_rpn_loc: 0.04282  time: 1.4618  data_time: 0.0306  lr: 0.001  max_mem: 7206M\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[01/02 16:19:42 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[01/02 16:19:42 d2.data.datasets.coco]: \u001b[0mLoaded 237 images in COCO format from ../../data/models/detectron2/no-augmentations/valid/_annotations.coco.json\n",
      "\u001b[32m[01/02 16:19:42 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/02 16:19:42 d2.data.common]: \u001b[0mSerializing 237 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/02 16:19:42 d2.data.common]: \u001b[0mSerialized dataset takes 0.08 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[01/02 16:19:42 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[01/02 16:19:42 d2.evaluation.evaluator]: \u001b[0mStart inference on 237 batches\n",
      "\u001b[32m[01/02 16:19:45 d2.evaluation.evaluator]: \u001b[0mInference done 11/237. Dataloading: 0.0003 s/iter. Inference: 0.1593 s/iter. Eval: 0.0000 s/iter. Total: 0.1597 s/iter. ETA=0:00:36\n",
      "\u001b[32m[01/02 16:19:50 d2.evaluation.evaluator]: \u001b[0mInference done 43/237. Dataloading: 0.0004 s/iter. Inference: 0.1598 s/iter. Eval: 0.0000 s/iter. Total: 0.1603 s/iter. ETA=0:00:31\n",
      "\u001b[32m[01/02 16:19:55 d2.evaluation.evaluator]: \u001b[0mInference done 75/237. Dataloading: 0.0004 s/iter. Inference: 0.1599 s/iter. Eval: 0.0000 s/iter. Total: 0.1604 s/iter. ETA=0:00:25\n",
      "\u001b[32m[01/02 16:20:00 d2.evaluation.evaluator]: \u001b[0mInference done 105/237. Dataloading: 0.0004 s/iter. Inference: 0.1621 s/iter. Eval: 0.0000 s/iter. Total: 0.1626 s/iter. ETA=0:00:21\n",
      "\u001b[32m[01/02 16:20:05 d2.evaluation.evaluator]: \u001b[0mInference done 133/237. Dataloading: 0.0004 s/iter. Inference: 0.1669 s/iter. Eval: 0.0000 s/iter. Total: 0.1673 s/iter. ETA=0:00:17\n",
      "\u001b[32m[01/02 16:20:10 d2.evaluation.evaluator]: \u001b[0mInference done 159/237. Dataloading: 0.0004 s/iter. Inference: 0.1717 s/iter. Eval: 0.0000 s/iter. Total: 0.1722 s/iter. ETA=0:00:13\n",
      "\u001b[32m[01/02 16:20:15 d2.evaluation.evaluator]: \u001b[0mInference done 187/237. Dataloading: 0.0004 s/iter. Inference: 0.1735 s/iter. Eval: 0.0000 s/iter. Total: 0.1740 s/iter. ETA=0:00:08\n",
      "\u001b[32m[01/02 16:20:20 d2.evaluation.evaluator]: \u001b[0mInference done 217/237. Dataloading: 0.0004 s/iter. Inference: 0.1726 s/iter. Eval: 0.0000 s/iter. Total: 0.1730 s/iter. ETA=0:00:03\n",
      "\u001b[32m[01/02 16:20:24 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:40.291862 (0.173672 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/02 16:20:24 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:40 (0.172615 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/02 16:20:24 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[01/02 16:20:24 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to runs/train/no-augmentations\\coco_instances_results.json\n",
      "\u001b[32m[01/02 16:20:24 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[01/02 16:20:24 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[01/02 16:20:24 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.01 seconds.\n",
      "\u001b[32m[01/02 16:20:24 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[01/02 16:20:24 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.01 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      "\u001b[32m[01/02 16:20:24 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| 0.000 | 0.000  | 0.000  | 0.000 | 0.000 | 0.000 |\n",
      "\u001b[32m[01/02 16:20:24 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP   | category   | AP    |\n",
      "|:-----------|:-----|:-----------|:------|\n",
      "| litter     | nan  | litter     | 0.000 |\n",
      "\u001b[32m[01/02 16:20:24 d2.engine.defaults]: \u001b[0mEvaluation results for valid_data in csv format:\n",
      "\u001b[32m[01/02 16:20:24 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[01/02 16:20:24 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[01/02 16:20:24 d2.evaluation.testing]: \u001b[0mcopypaste: 0.0000,0.0000,0.0000,0.0000,0.0000,0.0000\n",
      "\u001b[32m[01/02 16:20:24 d2.utils.events]: \u001b[0m eta: 0:07:09  iter: 1199  total_loss: 0.04625  loss_cls: 7.991e-05  loss_box_reg: 0  loss_rpn_cls: 0.005903  loss_rpn_loc: 0.0417  time: 1.4604  data_time: 0.0309  lr: 0.001  max_mem: 7206M\n",
      "\u001b[32m[01/02 16:21:36 d2.utils.events]: \u001b[0m eta: 0:06:41  iter: 1219  total_loss: 0.04297  loss_cls: 8.934e-05  loss_box_reg: 0  loss_rpn_cls: 0.006099  loss_rpn_loc: 0.03474  time: 1.4954  data_time: 0.0303  lr: 0.001  max_mem: 7206M\n",
      "\u001b[32m[01/02 16:22:45 d2.utils.events]: \u001b[0m eta: 0:06:12  iter: 1239  total_loss: 0.05075  loss_cls: 7.307e-05  loss_box_reg: 0  loss_rpn_cls: 0.007079  loss_rpn_loc: 0.04044  time: 1.5267  data_time: 0.0305  lr: 0.001  max_mem: 7206M\n",
      "\u001b[32m[01/02 16:23:53 d2.utils.events]: \u001b[0m eta: 0:05:43  iter: 1259  total_loss: 0.04693  loss_cls: 7.449e-05  loss_box_reg: 0  loss_rpn_cls: 0.006667  loss_rpn_loc: 0.0401  time: 1.5572  data_time: 0.0296  lr: 0.001  max_mem: 7206M\n",
      "\u001b[32m[01/02 16:25:00 d2.utils.events]: \u001b[0m eta: 0:05:15  iter: 1279  total_loss: 0.05607  loss_cls: 9.571e-05  loss_box_reg: 0  loss_rpn_cls: 0.007851  loss_rpn_loc: 0.04815  time: 1.5852  data_time: 0.0299  lr: 0.001  max_mem: 7206M\n",
      "\u001b[32m[01/02 16:26:13 d2.utils.events]: \u001b[0m eta: 0:04:46  iter: 1299  total_loss: 0.05764  loss_cls: 8.477e-05  loss_box_reg: 0  loss_rpn_cls: 0.007316  loss_rpn_loc: 0.04447  time: 1.6171  data_time: 0.0311  lr: 0.001  max_mem: 7206M\n",
      "\u001b[32m[01/02 16:27:24 d2.utils.events]: \u001b[0m eta: 0:04:18  iter: 1319  total_loss: 0.04566  loss_cls: 6.293e-05  loss_box_reg: 0  loss_rpn_cls: 0.005016  loss_rpn_loc: 0.04141  time: 1.6460  data_time: 0.0307  lr: 0.001  max_mem: 7206M\n",
      "\u001b[32m[01/02 16:28:36 d2.utils.events]: \u001b[0m eta: 0:03:49  iter: 1339  total_loss: 0.04892  loss_cls: 6.645e-05  loss_box_reg: 0  loss_rpn_cls: 0.003349  loss_rpn_loc: 0.04397  time: 1.6753  data_time: 0.0296  lr: 0.001  max_mem: 7206M\n",
      "\u001b[32m[01/02 16:29:49 d2.utils.events]: \u001b[0m eta: 0:03:21  iter: 1359  total_loss: 0.05066  loss_cls: 8.208e-05  loss_box_reg: 0  loss_rpn_cls: 0.006475  loss_rpn_loc: 0.04463  time: 1.7042  data_time: 0.0304  lr: 0.001  max_mem: 7206M\n",
      "\u001b[32m[01/02 16:31:05 d2.utils.events]: \u001b[0m eta: 0:02:54  iter: 1379  total_loss: 0.05418  loss_cls: 4.761e-05  loss_box_reg: 0  loss_rpn_cls: 0.01015  loss_rpn_loc: 0.04343  time: 1.7348  data_time: 0.0316  lr: 0.001  max_mem: 7206M\n",
      "\u001b[32m[01/02 16:32:16 d2.utils.events]: \u001b[0m eta: 0:02:27  iter: 1399  total_loss: 0.03554  loss_cls: 6.007e-05  loss_box_reg: 0  loss_rpn_cls: 0.005797  loss_rpn_loc: 0.02947  time: 1.7604  data_time: 0.0294  lr: 0.001  max_mem: 7206M\n",
      "\u001b[32m[01/02 16:33:24 d2.utils.events]: \u001b[0m eta: 0:01:59  iter: 1419  total_loss: 0.04934  loss_cls: 5.409e-05  loss_box_reg: 0  loss_rpn_cls: 0.006652  loss_rpn_loc: 0.04088  time: 1.7837  data_time: 0.0304  lr: 0.001  max_mem: 7206M\n",
      "\u001b[32m[01/02 16:34:21 d2.utils.events]: \u001b[0m eta: 0:01:30  iter: 1439  total_loss: 0.03995  loss_cls: 6.79e-05  loss_box_reg: 0  loss_rpn_cls: 0.005964  loss_rpn_loc: 0.03325  time: 1.7987  data_time: 0.0305  lr: 0.001  max_mem: 7206M\n",
      "\u001b[32m[01/02 16:34:48 d2.utils.events]: \u001b[0m eta: 0:00:59  iter: 1459  total_loss: 0.04245  loss_cls: 6.099e-05  loss_box_reg: 0  loss_rpn_cls: 0.005776  loss_rpn_loc: 0.03777  time: 1.7924  data_time: 0.0310  lr: 0.001  max_mem: 7206M\n",
      "\u001b[32m[01/02 16:35:14 d2.utils.events]: \u001b[0m eta: 0:00:29  iter: 1479  total_loss: 0.05075  loss_cls: 7.471e-05  loss_box_reg: 0  loss_rpn_cls: 0.008095  loss_rpn_loc: 0.04346  time: 1.7858  data_time: 0.0322  lr: 0.001  max_mem: 7206M\n",
      "\u001b[32m[01/02 16:36:22 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 1499  total_loss: 0.04611  loss_cls: 6.77e-05  loss_box_reg: 0  loss_rpn_cls: 0.00575  loss_rpn_loc: 0.04293  time: 1.8064  data_time: 0.0308  lr: 0.001  max_mem: 7206M\n",
      "\u001b[32m[01/02 16:36:22 d2.engine.hooks]: \u001b[0mOverall training speed: 1498 iterations in 0:45:06 (1.8065 s / it)\n",
      "\u001b[32m[01/02 16:36:22 d2.engine.hooks]: \u001b[0mTotal training time: 0:48:01 (0:02:54 on hooks)\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[01/02 16:36:22 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[01/02 16:36:22 d2.data.datasets.coco]: \u001b[0mLoaded 237 images in COCO format from ../../data/models/detectron2/no-augmentations/valid/_annotations.coco.json\n",
      "\u001b[32m[01/02 16:36:22 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/02 16:36:22 d2.data.common]: \u001b[0mSerializing 237 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/02 16:36:22 d2.data.common]: \u001b[0mSerialized dataset takes 0.08 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[01/02 16:36:22 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[01/02 16:36:22 d2.evaluation.evaluator]: \u001b[0mStart inference on 237 batches\n",
      "\u001b[32m[01/02 16:36:28 d2.evaluation.evaluator]: \u001b[0mInference done 11/237. Dataloading: 0.0003 s/iter. Inference: 0.4676 s/iter. Eval: 0.0000 s/iter. Total: 0.4679 s/iter. ETA=0:01:45\n",
      "\u001b[32m[01/02 16:36:34 d2.evaluation.evaluator]: \u001b[0mInference done 21/237. Dataloading: 0.0003 s/iter. Inference: 0.5291 s/iter. Eval: 0.0000 s/iter. Total: 0.5296 s/iter. ETA=0:01:54\n",
      "\u001b[32m[01/02 16:36:39 d2.evaluation.evaluator]: \u001b[0mInference done 29/237. Dataloading: 0.0003 s/iter. Inference: 0.5766 s/iter. Eval: 0.0000 s/iter. Total: 0.5770 s/iter. ETA=0:02:00\n",
      "\u001b[32m[01/02 16:36:44 d2.evaluation.evaluator]: \u001b[0mInference done 40/237. Dataloading: 0.0003 s/iter. Inference: 0.5430 s/iter. Eval: 0.0000 s/iter. Total: 0.5435 s/iter. ETA=0:01:47\n",
      "\u001b[32m[01/02 16:36:50 d2.evaluation.evaluator]: \u001b[0mInference done 51/237. Dataloading: 0.0003 s/iter. Inference: 0.5308 s/iter. Eval: 0.0000 s/iter. Total: 0.5312 s/iter. ETA=0:01:38\n",
      "\u001b[32m[01/02 16:36:55 d2.evaluation.evaluator]: \u001b[0mInference done 61/237. Dataloading: 0.0003 s/iter. Inference: 0.5282 s/iter. Eval: 0.0000 s/iter. Total: 0.5286 s/iter. ETA=0:01:33\n",
      "\u001b[32m[01/02 16:37:00 d2.evaluation.evaluator]: \u001b[0mInference done 73/237. Dataloading: 0.0003 s/iter. Inference: 0.5121 s/iter. Eval: 0.0000 s/iter. Total: 0.5126 s/iter. ETA=0:01:24\n",
      "\u001b[32m[01/02 16:37:05 d2.evaluation.evaluator]: \u001b[0mInference done 84/237. Dataloading: 0.0003 s/iter. Inference: 0.5062 s/iter. Eval: 0.0000 s/iter. Total: 0.5067 s/iter. ETA=0:01:17\n",
      "\u001b[32m[01/02 16:37:10 d2.evaluation.evaluator]: \u001b[0mInference done 96/237. Dataloading: 0.0003 s/iter. Inference: 0.4945 s/iter. Eval: 0.0000 s/iter. Total: 0.4950 s/iter. ETA=0:01:09\n",
      "\u001b[32m[01/02 16:37:15 d2.evaluation.evaluator]: \u001b[0mInference done 108/237. Dataloading: 0.0003 s/iter. Inference: 0.4855 s/iter. Eval: 0.0000 s/iter. Total: 0.4860 s/iter. ETA=0:01:02\n",
      "\u001b[32m[01/02 16:37:21 d2.evaluation.evaluator]: \u001b[0mInference done 120/237. Dataloading: 0.0003 s/iter. Inference: 0.4816 s/iter. Eval: 0.0000 s/iter. Total: 0.4821 s/iter. ETA=0:00:56\n",
      "\u001b[32m[01/02 16:37:26 d2.evaluation.evaluator]: \u001b[0mInference done 131/237. Dataloading: 0.0003 s/iter. Inference: 0.4813 s/iter. Eval: 0.0000 s/iter. Total: 0.4817 s/iter. ETA=0:00:51\n",
      "\u001b[32m[01/02 16:37:31 d2.evaluation.evaluator]: \u001b[0mInference done 142/237. Dataloading: 0.0003 s/iter. Inference: 0.4817 s/iter. Eval: 0.0000 s/iter. Total: 0.4821 s/iter. ETA=0:00:45\n",
      "\u001b[32m[01/02 16:37:36 d2.evaluation.evaluator]: \u001b[0mInference done 153/237. Dataloading: 0.0003 s/iter. Inference: 0.4814 s/iter. Eval: 0.0000 s/iter. Total: 0.4818 s/iter. ETA=0:00:40\n",
      "\u001b[32m[01/02 16:37:42 d2.evaluation.evaluator]: \u001b[0mInference done 164/237. Dataloading: 0.0003 s/iter. Inference: 0.4820 s/iter. Eval: 0.0000 s/iter. Total: 0.4824 s/iter. ETA=0:00:35\n",
      "\u001b[32m[01/02 16:37:47 d2.evaluation.evaluator]: \u001b[0mInference done 176/237. Dataloading: 0.0003 s/iter. Inference: 0.4776 s/iter. Eval: 0.0000 s/iter. Total: 0.4780 s/iter. ETA=0:00:29\n",
      "\u001b[32m[01/02 16:37:52 d2.evaluation.evaluator]: \u001b[0mInference done 188/237. Dataloading: 0.0003 s/iter. Inference: 0.4738 s/iter. Eval: 0.0000 s/iter. Total: 0.4742 s/iter. ETA=0:00:23\n",
      "\u001b[32m[01/02 16:37:57 d2.evaluation.evaluator]: \u001b[0mInference done 200/237. Dataloading: 0.0003 s/iter. Inference: 0.4711 s/iter. Eval: 0.0000 s/iter. Total: 0.4716 s/iter. ETA=0:00:17\n",
      "\u001b[32m[01/02 16:38:02 d2.evaluation.evaluator]: \u001b[0mInference done 211/237. Dataloading: 0.0003 s/iter. Inference: 0.4715 s/iter. Eval: 0.0000 s/iter. Total: 0.4720 s/iter. ETA=0:00:12\n",
      "\u001b[32m[01/02 16:38:08 d2.evaluation.evaluator]: \u001b[0mInference done 221/237. Dataloading: 0.0003 s/iter. Inference: 0.4745 s/iter. Eval: 0.0000 s/iter. Total: 0.4749 s/iter. ETA=0:00:07\n",
      "\u001b[32m[01/02 16:38:13 d2.evaluation.evaluator]: \u001b[0mInference done 232/237. Dataloading: 0.0003 s/iter. Inference: 0.4753 s/iter. Eval: 0.0000 s/iter. Total: 0.4758 s/iter. ETA=0:00:02\n",
      "\u001b[32m[01/02 16:38:17 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:51.552806 (0.480831 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/02 16:38:17 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:51 (0.479710 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/02 16:38:17 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[01/02 16:38:17 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to runs/train/no-augmentations\\coco_instances_results.json\n",
      "\u001b[32m[01/02 16:38:17 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[01/02 16:38:17 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[01/02 16:38:17 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.01 seconds.\n",
      "\u001b[32m[01/02 16:38:17 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[01/02 16:38:17 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.00 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      "\u001b[32m[01/02 16:38:17 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| 0.000 | 0.000  | 0.000  | 0.000 | 0.000 | 0.000 |\n",
      "\u001b[32m[01/02 16:38:17 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP   | category   | AP    |\n",
      "|:-----------|:-----|:-----------|:------|\n",
      "| litter     | nan  | litter     | 0.000 |\n",
      "\u001b[32m[01/02 16:38:17 d2.engine.defaults]: \u001b[0mEvaluation results for valid_data in csv format:\n",
      "\u001b[32m[01/02 16:38:17 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[01/02 16:38:17 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[01/02 16:38:17 d2.evaluation.testing]: \u001b[0mcopypaste: 0.0000,0.0000,0.0000,0.0000,0.0000,0.0000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.evaluation import COCOEvaluator\n",
    "\n",
    "class CocoTrainer(DefaultTrainer):\n",
    "\n",
    "  @classmethod\n",
    "  def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    output_folder = output_dir\n",
    "    return COCOEvaluator(dataset_name, cfg, False, output_folder)\n",
    "\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(starting_config))\n",
    "cfg.OUTPUT_DIR = output_dir\n",
    "\n",
    "cfg.DATASETS.TRAIN = (train_data,)\n",
    "cfg.DATASETS.TEST = (valid_data,)\n",
    "cfg.DATALOADER.NUM_WORKERS = 1\n",
    "\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(starting_config)\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = batch_size_per_image\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = n_classes\n",
    "\n",
    "cfg.SOLVER.IMS_PER_BATCH = images_per_batch\n",
    "cfg.SOLVER.BASE_LR = learning_rate\n",
    "cfg.SOLVER.WARMUP_ITERS = warmup_iters\n",
    "cfg.SOLVER.MAX_ITER = iters\n",
    "cfg.SOLVER.STEPS = steps\n",
    "\n",
    "cfg.TEST.EVAL_PERIOD = eval_iters\n",
    "\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = CocoTrainer(cfg)\n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[01/02 16:40:31 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[01/02 16:40:31 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[01/02 16:40:31 d2.data.datasets.coco]: \u001b[0mLoaded 119 images in COCO format from ../../data/models/detectron2/no-augmentations/test/_annotations.coco.json\n",
      "\u001b[32m[01/02 16:40:31 d2.data.build]: \u001b[0mDistribution of instances among all 2 categories:\n",
      "\u001b[36m|  category  | #instances   |  category  | #instances   |\n",
      "|:----------:|:-------------|:----------:|:-------------|\n",
      "|   litter   | 0            |   litter   | 248          |\n",
      "|            |              |            |              |\n",
      "|   total    | 248          |            |              |\u001b[0m\n",
      "\u001b[32m[01/02 16:40:31 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/02 16:40:31 d2.data.common]: \u001b[0mSerializing 119 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/02 16:40:31 d2.data.common]: \u001b[0mSerialized dataset takes 0.04 MiB\n",
      "\u001b[32m[01/02 16:40:31 d2.evaluation.evaluator]: \u001b[0mStart inference on 119 batches\n",
      "\u001b[32m[01/02 16:40:39 d2.evaluation.evaluator]: \u001b[0mInference done 11/119. Dataloading: 0.0003 s/iter. Inference: 0.6652 s/iter. Eval: 0.0001 s/iter. Total: 0.6656 s/iter. ETA=0:01:11\n",
      "\u001b[32m[01/02 16:40:44 d2.evaluation.evaluator]: \u001b[0mInference done 19/119. Dataloading: 0.0003 s/iter. Inference: 0.6598 s/iter. Eval: 0.0001 s/iter. Total: 0.6602 s/iter. ETA=0:01:06\n",
      "\u001b[32m[01/02 16:40:50 d2.evaluation.evaluator]: \u001b[0mInference done 29/119. Dataloading: 0.0004 s/iter. Inference: 0.6021 s/iter. Eval: 0.0001 s/iter. Total: 0.6026 s/iter. ETA=0:00:54\n",
      "\u001b[32m[01/02 16:40:55 d2.evaluation.evaluator]: \u001b[0mInference done 42/119. Dataloading: 0.0003 s/iter. Inference: 0.5360 s/iter. Eval: 0.0001 s/iter. Total: 0.5365 s/iter. ETA=0:00:41\n",
      "\u001b[32m[01/02 16:41:00 d2.evaluation.evaluator]: \u001b[0mInference done 54/119. Dataloading: 0.0003 s/iter. Inference: 0.5087 s/iter. Eval: 0.0001 s/iter. Total: 0.5092 s/iter. ETA=0:00:33\n",
      "\u001b[32m[01/02 16:41:05 d2.evaluation.evaluator]: \u001b[0mInference done 66/119. Dataloading: 0.0003 s/iter. Inference: 0.4927 s/iter. Eval: 0.0001 s/iter. Total: 0.4932 s/iter. ETA=0:00:26\n",
      "\u001b[32m[01/02 16:41:10 d2.evaluation.evaluator]: \u001b[0mInference done 78/119. Dataloading: 0.0003 s/iter. Inference: 0.4821 s/iter. Eval: 0.0000 s/iter. Total: 0.4825 s/iter. ETA=0:00:19\n",
      "\u001b[32m[01/02 16:41:15 d2.evaluation.evaluator]: \u001b[0mInference done 90/119. Dataloading: 0.0003 s/iter. Inference: 0.4744 s/iter. Eval: 0.0000 s/iter. Total: 0.4749 s/iter. ETA=0:00:13\n",
      "\u001b[32m[01/02 16:41:21 d2.evaluation.evaluator]: \u001b[0mInference done 102/119. Dataloading: 0.0003 s/iter. Inference: 0.4686 s/iter. Eval: 0.0000 s/iter. Total: 0.4691 s/iter. ETA=0:00:07\n",
      "\u001b[32m[01/02 16:41:26 d2.evaluation.evaluator]: \u001b[0mInference done 113/119. Dataloading: 0.0003 s/iter. Inference: 0.4681 s/iter. Eval: 0.0000 s/iter. Total: 0.4685 s/iter. ETA=0:00:02\n",
      "\u001b[32m[01/02 16:41:28 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:52.985133 (0.464782 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/02 16:41:28 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:52 (0.463319 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/02 16:41:28 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[01/02 16:41:28 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to runs/train/no-augmentations\\coco_instances_results.json\n",
      "\u001b[32m[01/02 16:41:28 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[01/02 16:41:28 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[01/02 16:41:28 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.00 seconds.\n",
      "\u001b[32m[01/02 16:41:28 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[01/02 16:41:28 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.00 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      "\u001b[32m[01/02 16:41:28 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| 0.000 | 0.000  | 0.000  | 0.000 | 0.000 | 0.000 |\n",
      "\u001b[32m[01/02 16:41:28 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP   | category   | AP    |\n",
      "|:-----------|:-----|:-----------|:------|\n",
      "| litter     | nan  | litter     | 0.000 |\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('bbox',\n",
       "              {'AP': 0.0,\n",
       "               'AP50': 0.0,\n",
       "               'AP75': 0.0,\n",
       "               'APs': 0.0,\n",
       "               'APm': 0.0,\n",
       "               'APl': 0.0,\n",
       "               'AP-litter': 0.0})])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from detectron2.data import MetadataCatalog, build_detection_test_loader\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.engine import DefaultPredictor\n",
    "\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, final_model_file)\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = confidence_threshold\n",
    "predictor = DefaultPredictor(cfg)\n",
    "evaluator = COCOEvaluator(test_data, cfg, False, output_dir=output_dir)\n",
    "val_loader = build_detection_test_loader(cfg, test_data)\n",
    "inference_on_dataset(trainer.model, val_loader, evaluator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import cv2\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "\n",
    "cfg.DATASETS.TEST = (test_data, )\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, final_model_file)\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = confidence_threshold\n",
    "\n",
    "predictor = DefaultPredictor(cfg)\n",
    "test_metadata = MetadataCatalog.get(test_data)\n",
    "\n",
    "n_images = 3\n",
    "title = \"Faster RCNN Litter Detection\"\n",
    "\n",
    "for imageName in glob.glob(f\"{data_dir}/test/*jpg\")[:n_images]:\n",
    "  im = cv2.imread(imageName)\n",
    "  outputs = predictor(im)\n",
    "  v = Visualizer(im[:, :, ::-1], metadata=test_metadata)\n",
    "  out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "  img = out.get_image()[:, :, ::-1]\n",
    "  cv2.imshow(title, img)\n",
    "  cv2.waitKey(0)\n",
    "  cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cf27d97dcf4be97ac4b24b0958c44b40d000600328bb3db0f801b46df5aa5b85"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
